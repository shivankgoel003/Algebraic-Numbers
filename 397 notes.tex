\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[total={6.5in,9in}]{geometry} % set text height and width: 1-in margins all around
\usepackage{tabularx}
\usepackage{mdframed}
\newenvironment{proofbox}
  {\begin{mdframed}[linewidth=1pt,linecolor=black,backgroundcolor=white]\noindent\ignorespaces}
  {\end{mdframed}}
\usepackage{amsthm,amsmath,amssymb,amsfonts}
\usepackage{enumerate} 
\newcommand\tab[1][0.5cm]{\hspace*{#1}}
\usepackage{hyperref} % package for in-text hyperlinks
\hypersetup{colorlinks=true,
linkcolor=blue,
urlcolor=blue}
\usepackage{listings}
\lstdefinestyle{Python}{
  language=Python,
  basicstyle=\small\ttfamily,
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  backgroundcolor=\color{gray!10},
  frame=single,
  breaklines=true,
  showstringspaces=false,
  keywordstyle=\color{blue},
  commentstyle=\color{green!60!black},
  stringstyle=\color{red},
  identifierstyle=\color{black}
}

\usepackage{thmtools}
\usepackage{graphicx}
\graphicspath{{C:/Users/shiva/OneDrive/Desktop/3rd year/Winter/mat402/assignments}}
\usepackage{setspace}

\usepackage{float}

\usepackage[english]{babel}
\usepackage{framed}
\usepackage[dvipsnames]{xcolor}
\usepackage{environ}
\usepackage{tcolorbox}
\tcbuselibrary{theorems,skins,breakable}

\setstretch{1.2}
\geometry{
    textheight=9in,
    textwidth=5.5in,
    top=1in,
    headheight=12pt,
    headsep=25pt,
    footskip=30pt
}


% ------------------------------------------------------------------------------

\newtcolorbox{myBox}[3][]{
arc=5mm,
lower separated=false,
fonttitle=\bfseries,
colbacktitle=green!10,
coltitle=green!50!black,
enhanced,
attach boxed title to top left={xshift=0.5cm,
        yshift=-2mm},
colframe=green!50!black,
colback=green!10,
overlay={
\node[draw=green!50!black,thick,
%inner sep=2mm,
fill= green!10,rounded corners=1mm, 
yshift=0pt, 
xshift=-0.5cm, 
left, 
text=green!50!black,
anchor=east,
font=\bfseries] 
at (frame.north east) {#3};},
title=#2,#1}


\usepackage{tikz} % For plots, drawings

%% command to produce (mod n) notation
%  better spacing than \pmod
\newcommand{\Mod}[1]{\ \left(\mathrm{mod}\ #1\right)} 

\usepackage{fancyhdr} % package for headers and footers
\pagestyle{fancy}

% Definition
\newtcbtheorem{mydefinition}{Definition}
{
    enhanced,
    frame hidden,
    titlerule=0mm,
    toptitle=1mm,
    bottomtitle=1mm,
    fonttitle=\bfseries\large,
    coltitle=black,
    colbacktitle=green!20!white,
    colback=green!10!white,
}{defn}

\NewDocumentCommand{\defn}{m+m}{
    \begin{mydefinition}{#1}{}
        #2
    \end{mydefinition}
}

\NewDocumentCommand{\defnr}{mm+m}{
    \begin{mydefinition}{#1}{#2}
        #3
    \end{mydefinition}
}

% Theorem
\newtcbtheorem{mytheorem}{Theorem}
{
    enhanced,
    frame hidden,
    titlerule=0mm,
    toptitle=1mm,
    bottomtitle=1mm,
    fonttitle=\bfseries\large,
    coltitle=black,
    colbacktitle=cyan!20!white,
    colback=cyan!10!white,
}{thm}

\NewDocumentCommand{\thm}{m+m}{
    \begin{mytheorem}{#1}{}
        #2
    \end{mytheorem}
}

\NewDocumentCommand{\thmr}{mm+m}{
    \begin{mytheorem}{#1}{#2}
        #3
    \end{mytheorem}
}

% Lemma
\newtcbtheorem[use counter from=mydefinition]{mylemma}{Lemma}
{
    enhanced,
    frame hidden,
    titlerule=0mm,
    toptitle=1mm,
    bottomtitle=1mm,
    fonttitle=\bfseries\large,
    coltitle=black,
    colbacktitle=violet!20!white,
    colback=violet!10!white,
}{lem}

\NewDocumentCommand{\lem}{m+m}{
    \begin{mylemma}{#1}{}
        #2
    \end{mylemma}
}

\newenvironment{lempf}{
	{\noindent{\it \textbf{Proof for Lemma}}}
	\tcolorbox[blanker,breakable,left=5mm,parbox=false,
    before upper={\parindent15pt},
    after skip=10pt,
	borderline west={1mm}{0pt}{violet!20!white}]
}{
    \textcolor{violet!20!white}{\hbox{}\nobreak\hfill$\blacksquare$} 
    \endtcolorbox
}

\NewDocumentCommand{\lemp}{m+m+m}{
    \begin{mylemma}{#1}{}
        #2
    \end{mylemma}

    \begin{lempf}
        #3
    \end{lempf}
}

% Corollary
\newtcbtheorem[use counter from=mydefinition]{mycorollary}{Corollary}
{
    enhanced,
    frame hidden,
    titlerule=0mm,
    toptitle=1mm,
    bottomtitle=1mm,
    fonttitle=\bfseries\large,
    coltitle=black,
    colbacktitle=orange!20!white,
    colback=orange!10!white,
}{cor}

\NewDocumentCommand{\cor}{+m}{
    \begin{mycorollary}{}{}
        #1
    \end{mycorollary}
}

\newenvironment{corpf}{
	{\noindent{\it \textbf{Proof for Corollary.}}}
	\tcolorbox[blanker,breakable,left=5mm,parbox=false,
    before upper={\parindent15pt},
    after skip=10pt,
	borderline west={1mm}{0pt}{orange!20!white}]
}{
    \textcolor{orange!20!white}{\hbox{}\nobreak\hfill$\blacksquare$} 
    \endtcolorbox
}

\NewDocumentCommand{\corp}{m+m+m}{
    \begin{mycorollary}{}{}
        #1
    \end{mycorollary}

    \begin{corpf}
        #2
    \end{corpf}
}

% Proposition
\newtcbtheorem[use counter from=mydefinition]{myproposition}{Proposition}
{
    enhanced,
    frame hidden,
    titlerule=0mm,
    toptitle=1mm,
    bottomtitle=1mm,
    fonttitle=\bfseries\large,
    coltitle=black,
    colbacktitle=yellow!30!white,
    colback=yellow!20!white,
}{prop}

\NewDocumentCommand{\prop}{+m}{
    \begin{myproposition}{}{}
        #1
    \end{myproposition}
}

\newenvironment{proppf}{
	{\noindent{\it \textbf{Proof for Proposition.}}}
	\tcolorbox[blanker,breakable,left=5mm,parbox=false,
    before upper={\parindent15pt},
    after skip=10pt,
	borderline west={1mm}{0pt}{yellow!30!white}]
}{
    \textcolor{yellow!30!white}{\hbox{}\nobreak\hfill$\blacksquare$} 
    \endtcolorbox
}

\NewDocumentCommand{\propp}{+m+m}{
    \begin{myproposition}{}{}
        #1
    \end{myproposition}

    \begin{proppf}
        #2
    \end{proppf}
}

% Claim
\newtcbtheorem[use counter from=mydefinition]{myclaim}{Claim}
{
    enhanced,
    frame hidden,
    titlerule=0mm,
    toptitle=1mm,
    bottomtitle=1mm,
    fonttitle=\bfseries\large,
    coltitle=black,
    colbacktitle=pink!30!white,
    colback=pink!20!white,
}{clm}


\NewDocumentCommand{\clm}{m+m}{
    \begin{myclaim*}{#1}{}
        #2
    \end{myclaim*}
}

\newenvironment{clmpf}{
	{\noindent{\it \textbf{Proof for Claim.}}}
	\tcolorbox[blanker,breakable,left=5mm,parbox=false,
    before upper={\parindent15pt},
    after skip=10pt,
	borderline west={1mm}{0pt}{pink!30!white}]
}{
    \textcolor{pink!30!white}{\hbox{}\nobreak\hfill$\blacksquare$} 
    \endtcolorbox
}

\NewDocumentCommand{\clmp}{m+m+m}{
    \begin{myclaim*}{#1}{}
        #2
    \end{myclaim*}

    \begin{clmpf}
        #3
    \end{clmpf}
}

% Fact
\newtcbtheorem[use counter from=mydefinition]{myfact}{Fact}
{
    enhanced,
    frame hidden,
    titlerule=0mm,
    toptitle=1mm,
    bottomtitle=1mm,
    fonttitle=\bfseries\large,
    coltitle=black,
    colbacktitle=purple!20!white,
    colback=purple!10!white,
}{fact}

\NewDocumentCommand{\fact}{+m}{
    \begin{myfact}{}{}
        #1
    \end{myfact}
}


% Proof
\NewDocumentCommand{\pf}{+m}{
    \begin{proof}
        [\noindent\textbf{Proof.}]
        #1
    \end{proof}
}

% Example
\newenvironment{example}{%
    \par
    \vspace{5pt}
	\begin{minipage}{\textwidth}
		\noindent\textbf{Example.}
		\tcolorbox[blanker,breakable,left=5mm,parbox=false,
	    before upper={\parindent15pt},
	    after skip=10pt,
		borderline west={1mm}{0pt}{cyan!10!white}]
}{%
		\endtcolorbox
	\end{minipage}
    \vspace{5pt}
}

\NewDocumentCommand{\ex}{+m}{
    \begin{example}
        #1
    \end{example}
}


% Remark
\NewDocumentCommand{\rmk}{+m}{
    {\it \color{blue!50!white}#1}
}

\newenvironment{remark}{
    \par
    \vspace{5pt}
    \begin{minipage}{\textwidth}
        {\par\noindent{\textbf{Remark.}}}
        \tcolorbox[blanker,breakable,left=5mm,
        before skip=10pt,after skip=10pt,
        borderline west={1mm}{0pt}{cyan!10!white}]
}{
        \endtcolorbox
    \end{minipage}
    \vspace{5pt}
}

\NewDocumentCommand{\rmkb}{+m}{
    \begin{remark}
        #1
    \end{remark}
}

\newcommand{\lcm}{\operatorname{lcm}}




\newcommand{\bC}{\mathbb{C}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bN}{\mathbf{N}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bR}{\mathbf{R}}
\newcommand{\bZ}{\mathbb{Z}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\sA}{\mathscr{A}}
\newcommand{\sB}{\mathscr{B}}
\newcommand{\sC}{\mathscr{C}}
\newcommand{\sL}{\mathscr{L}}
\newcommand{\sP}{\mathscr{P}}

\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\one}{\mathbf{1}}
\newcommand{\pr}{\mathrm{Pr}}
\newcommand{\var}{\mathrm{Var}}

\newcommand{\ax}[1]{\operatorname{\mathsf{#1}}}

\title{\vspace{3cm} \textbf{Algebraic Numbers} \\[0.5cm] \large Further Studies in Mathematics}
\author{\textbf{Shivank Goel} \\ \textit{University of Toronto Mississauga} \\ Supervisor: Professor Marina Tvalvazade}
\date{\vspace{2cm} Fall 2024}

\begin{document}

% Cover page
\maketitle
\thispagestyle{empty} % remove page number on cover page
\newpage

% Table of Contents (optional)
\tableofcontents
\newpage



\section{Primitive Polynomial}
A \textbf{primitive polynomial} is a polynomial with integer coefficients in $\mathbb{Z}[x]$ such that the greatest common divisor (GCD) of its coefficients is 1. In other words, a polynomial is primitive if its coefficients have no common prime divisor.

\textbf{Example of a Primitive Polynomial:}
\[
f(x) = 2x^2 + 3x + 1
\]
Here, the GCD of the coefficients $\{2, 3, 1\}$ is 1, so this polynomial is primitive.

\textbf{Non-Example (Not Primitive):}
\[
g(x) = 2x^2 + 4x + 6
\]
In this case, the GCD of the coefficients $\{2, 4, 6\}$ is 2, so this polynomial is not primitive.

\textbf{Key Concept:} A primitive polynomial is related to the content of the polynomial, which is the GCD of its coefficients. If the content is 1, the polynomial is primitive.

\section{Irreducible Polynomial}
A \textbf{polynomial is irreducible} if it cannot be factored into the product of two non-constant polynomials with coefficients in the same ring (e.g., $\mathbb{Z}[x]$ or $\mathbb{Q}[x]$).

\textbf{Example of an Irreducible Polynomial (over $\mathbb{Q}$):}
\[
f(x) = x^2 + 1
\]
This polynomial cannot be factored over $\mathbb{Q}[x]$ into lower-degree polynomials, so it is irreducible over $\mathbb{Q}$.

\textbf{Non-Example (Not Irreducible):}
\[
g(x) = x^2 - 1 = (x - 1)(x + 1)
\]
Here, $g(x)$ can be factored into two polynomials of degree 1, so it is not irreducible.

\textbf{Key Concept:} Irreducibility refers to the inability to factor a polynomial into lower-degree polynomials with coefficients in the same field or ring.

\section*{Summary}
\begin{itemize}
    \item \textbf{Primitive Polynomial}: Focuses on the \textbf{coefficients} of the polynomial. A polynomial is primitive if the GCD of its coefficients is 1.
    \item \textbf{Irreducible Polynomial}: Focuses on the \textbf{factorization} of the polynomial. A polynomial is irreducible if it cannot be factored into the product of two non-constant polynomials with coefficients in the same field or ring.
\end{itemize}

A polynomial can be both primitive and irreducible, but these properties are independent of each other:
\begin{itemize}
    \item A polynomial can be \textbf{primitive but reducible}, e.g., 
    \[
    f(x) = x^2 - 1 = (x - 1)(x + 1)
    \]
    Here, $f(x)$ is reducible but primitive, as the GCD of its coefficients is 1.
    
    \item A polynomial can be \textbf{irreducible but not primitive}, e.g.,
    \[
    g(x) = 2x^2 + 4x + 6
    \]
    This polynomial is irreducible over $\mathbb{Z}$, but not primitive, as the GCD of its coefficients is 2.
\end{itemize}


\thm{1}{
    Product of two primitive polynomials is primitive.
}

\begin{proofbox}
    Let $f(x), g(x) \in \mathbb{Z}[x]$ be primitive polynomials, i.e., $c(f(x)) = c(g(x)) = 1$, where $c(f(x))$ denotes the content of $f(x)$, which is the greatest common divisor of the coefficients of $f(x)$.
    
    Assume, for contradiction, that $h(x) = f(x)g(x)$ is not primitive. This would mean that $c(h(x)) \neq 1$, so there exists a prime $p$ such that $p$ divides all the coefficients of $h(x)$.

    Write $f(x) = a_0 + a_1x + \cdots + a_nx^n$ and $g(x) = b_0 + b_1x + \cdots + b_mx^m$, where $a_i, b_j \in \mathbb{Z}$. Since $f(x)$ and $g(x)$ are primitive, $p$ does not divide all the coefficients of either $f(x)$ or $g(x)$.

    Now consider the product:
    \[
    h(x) = f(x)g(x) = a_0b_0 + (a_0b_1 + a_1b_0)x + \cdots + a_nb_mx^{n+m}.
    \]
    By assumption, $p$ divides all the coefficients of $h(x)$. In particular, $p$ divides the constant term $a_0b_0$. Thus, $p$ must divide either $a_0$ or $b_0$, but not both (since $f(x)$ and $g(x)$ are primitive).

    Without loss of generality, assume $p \mid a_0$ but $p \nmid b_0$. Consider the next term in $h(x)$, which is $a_0b_1 + a_1b_0$. Since $p \mid a_0$ and $p \mid a_0b_1 + a_1b_0$, we must have $p \mid a_1b_0$. Since $p \nmid b_0$, it follows that $p \mid a_1$.

    Continuing in this way, we conclude that $p$ divides all the coefficients of $f(x)$. This contradicts the assumption that $f(x)$ is primitive.

    Similarly, if we had assumed $p \mid b_0$ and $p \nmid a_0$, we would have reached the conclusion that $p$ divides all the coefficients of $g(x)$, contradicting the fact that $g(x)$ is primitive.

    Therefore, our assumption that $h(x)$ is not primitive must be false, and so $h(x) = f(x)g(x)$ is primitive.
\end{proofbox}

\lem{Gauss Lemma}{If a monic polynomial $f(x)$ with integral 
coefficient factors into two monic 
polynomials with rational coefficient say 
$f(x) = g(x)h(x)$, then $g(x)$ and $h(x)$
have integral coefficients.} 
In other words, Reducibility over $Q$ implies reducibility over $Z$.
\begin{proofbox}
    Let $f(x) \in \mathbb{Z}[x]$.\\\\
    Given that $f(x)$ is reducible over $\mathbb{Q}$, we have $f(x) = g(x)h(x)$, where $g(x)$ and $h(x)$ are monic polynomials with rational coefficients, i.e. $g(x), h(x) \in \mathbb{Q}[x]$, with $\deg(g(x)) < \deg(f(x))$ and $\deg(h(x)) < \deg(f(x))$.\\\\
    Assume $f(x)$ is primitive.\\\\
    Since $g(x)$ and $h(x)$ have rational coefficients, let $a$ be the least common multiple of the denominators of the coefficients of $g(x)$, and $b$ the least common multiple of the denominators of the coefficients of $h(x)$.\\\\
    Now multiply both sides of the equation $f(x) = g(x)h(x)$ by $ab$ to clear the denominators. This gives:
    \[
    abf(x) = ag(x)bh(x)
    \]
    Let $g_1(x) = ag(x)$ and $h_1(x) = bh(x)$, where $g_1(x), h_1(x) \in \mathbb{Z}[x]$.\\\\
    Now let $c_1 = c(g_1(x))$ and $c_2 = c(h_1(x))$ be the contents of $g_1(x)$ and $h_1(x)$, respectively.\\\\
    We can then write:
    \[
    abf(x) = c_1g_2(x)c_2h_2(x)
    \]
    where $g_2(x)$ and $h_2(x)$ are primitive polynomials.\\\\
    Since the product of two primitive polynomials is primitive, $g_2(x)h_2(x)$ is primitive. Therefore, we have:
    \[
    ab = c_1c_2
    \]
    which implies that $f(x)$ is primitive.\\\\
    If $f(x)$ is not primitive, we can write $f(x) = cf_1(x)$, where $c = c(f(x))$ and $f_1(x)$ is primitive. Since $f_1(x)$ is reducible over $\mathbb{Z}$ (from the argument above), it follows that $f(x)$ is reducible over $\mathbb{Z}$ as well.\\\\
    This completes the proof.
    \end{proofbox}

    \section{Algebraic Number}
    \defn{Algebraic Number}{$x$ is algbraic if $x$ is root of 
    polynomial with integer coefficient, i.e.
    there are integers $a_n$, $a_{n-1}$, $\ldots$, $a_0$ such that
    \[
    a_nx^n + a_{n-1}x^{n-1} + \ldots + a_0 = 0
    \]}
    \ex{}{
        $x = \sqrt[3]{\frac{\sqrt{2} - 3}{5}}$ is algebraic? \\\\
        $x^3 = \frac{\sqrt{2} - 3}{5}$ \\\\
        $5x^3 + 3 = \sqrt{2}$ \\\\
        $25x^6 + 30x^3 + 9 = 2$ \\\\
        $25x^6 + 30x^3 + 7 = 0$ \\\\
        Therefore, $x$ is algebraic.
    }

    \defn{Transcendental Number}{A number that is not algebraic.}
    \ex{}{
        $\pi$, $e$ are transcendental numbers.
    }

    \defn{Algebraic Integers}{Algebraic Integers: These are a special subset of algebraic numbers that satisfy a monic polynomial (leading coefficient 1) with integer coefficients. for example, $\sqrt{2}$
      is also an algebraic integer because it satisfies $x^2 - 2 = 0$ monic polynomial with integer coefficients.}

    \defn{Unique Minimal Polynomial}{For any algebraic number \( g \), there is a unique minimal polynomial over \( \mathbb{Q} \). This is the irreducible monic polynomial that has \( g \) as a root. It is the polynomial of the smallest degree with rational coefficients that has \( g \) as a solution.}
    
    \ex{}{For example, for \( \sqrt{2} \), the minimal polynomial is \( x^2 - 2 \), since this is the simplest polynomial with rational coefficients that has \( \sqrt{2} \) as a root.
    As $x^2 - 2$ is irreducible over $\mathbb{Q}$, it is the unique minimal polynomial for $\sqrt{2}$. (if we factor it, we get $x^2 - 2 = (x - \sqrt{2})(x + \sqrt{2})$ i.e. it is reducible over $\mathbb{R}$ but not over $\mathbb{Q}$.)}

    \thm{}{For any algebraic number \( g \), there is a unique irreducible monic polynomial over \( \mathbb{Q} \) such that:
    \begin{enumerate}
        \item \( g \) satisfies the polynomial equation \( g(x) = 0 \),
        \item Any other polynomial over \( \mathbb{Q} \) that has \( g \) as a root is divisible by \( g(x) \).
    \end{enumerate}}
    \begin{proofbox}
 
Since \( g \) is an algebraic number, it satisfies some polynomial equation with rational coefficients. Out of all such polynomials, let’s choose one of the lowest degree, say \( G(x) \), such that \( G(g) = 0 \). If \( G(x) \) is not monic, we divide it by its leading coefficient to create a monic polynomial \( g(x) \). Now, \( g(x) \) is a monic polynomial of the lowest degree that has \( g \) as a root.

We now show that \( g(x) \) is irreducible over \( \mathbb{Q} \). Suppose, for contradiction, that \( g(x) \) can be factored as:
\[
g(x) = h_1(x) h_2(x)
\]
where \( h_1(x) \) and \( h_2(x) \) are lower-degree polynomials with rational coefficients. Since \( g \) is a root of \( g(x) \), one of \( h_1(g) = 0 \) or \( h_2(g) = 0 \) must be true. This would contradict the fact that \( g(x) \) was chosen to have the lowest degree, since \( h_1(x) \) or \( h_2(x) \) would have a smaller degree than \( g(x) \). Hence, \( g(x) \) must be irreducible.

Now, let \( f(x) \) be any polynomial over \( \mathbb{Q} \) that has \( g \) as a root (i.e., \( f(g) = 0 \)). Using the division algorithm for polynomials, we can write:
\[
f(x) = g(x) q(x) + r(x)
\]
where \( r(x) \) is a remainder with degree smaller than that of \( g(x) \). Since \( f(g) = g(g) = 0 \), it follows that:
\[
0 = f(g) = g(g) q(g) + r(g) = 0 + r(g)
\]
which implies that \( r(g) = 0 \). Since the degree of \( r(x) \) is less than that of \( g(x) \), the only way this is possible is if \( r(x) = 0 \). Therefore, \( f(x) \) must be divisible by \( g(x) \).

Finally, let's assume there is another irreducible monic polynomial, say \( g_1(x) \), such that \( g_1(g) = 0 \). Since \( g_1(x) \) has \( g \) as a root, and \( g(x) \) is the minimal polynomial, we know \( g_1(x) \) must divide \( g(x) \) and vice versa. Since both polynomials are irreducible and monic, this implies that \( g_1(x) = g(x) \). Thus, \( g(x) \) is unique.

Therefore, for any algebraic number \( g \), there exists a unique irreducible monic polynomial over \( \mathbb{Q} \), and any other polynomial over \( \mathbb{Q} \) with \( g \) as a root is divisible by this minimal polynomial.
    \end{proofbox}

    \defn{Degree of an Algebraic Number}{The degree of an algebraic number is the degree of its minimal polynomial over $\mathbb{Q}$.}
    \ex{}{The degree of $\sqrt{2}$ is 2, as its minimal polynomial is $x^2 - 2$.}


\thm{}{Among the rational numbers, the only ones that are algebraic
integers are the integers 0, $\pm 1$, $\pm 2$, $\pm 3$, $\ldots$}
\begin{proofbox}
   Any integer \( m \) is an algebraic integer because it satisfies the monic polynomial \( x - m = 0 \), which has integer coefficients.
    
    Now, consider a rational number \( \frac{m}{q} \), where \( m \) and \( q \) are integers and \( \gcd(m, q) = 1 \). If \( \frac{m}{q} \) is an algebraic integer, it must satisfy a monic polynomial with integer coefficients:
    \[
    \left( \frac{m}{q} \right)^n + b_{n-1} \left( \frac{m}{q} \right)^{n-1} + \dots + b_0 = 0
    \]
    where \( b_{n-1}, \dots, b_0 \) are integers. Multiplying through by \( q^n \) to clear the denominators, we obtain:
    \[
    m^n + b_{n-1} m^{n-1} q + \dots + b_0 q^n = 0
    \]
    This implies that \( q \) must divide \( m^n \). Since \( \gcd(m, q) = 1 \), the only possibility is \( q = \pm 1 \), which means \( \frac{m}{q} \) must be an integer.\\\\
        \textbf{Example:}
    - A rational integer: \( 2 \), because it satisfies \( x - 2 = 0 \) and is a rational number.\\
    - An algebraic integer but not a rational integer: \( \sqrt{2} \), because it satisfies \( x^2 - 2 = 0 \), but is not a rational number.
\end{proofbox}

\thm{}{The minimal equation of an algebraic integer is monic with
integral coefficients.}
\begin{proofbox}
    By definition, the minimal polynomial of an algebraic integer is \textbf{monic}, meaning its leading coefficient is 1. Therefore, it is assumed from the start that the polynomial is monic.

    Now, let \( g \) be an algebraic integer. Since \( g \) is an algebraic integer, it satisfies some polynomial equation with \textbf{integer coefficients}. Let this polynomial be \( f(x) \), such that:
    \[
    f(x) = a_n x^n + a_{n-1} x^{n-1} + \dots + a_1 x + a_0 = 0
    \]
    where \( a_n, a_{n-1}, \dots, a_0 \) are integers.
    
    Let \( g(x) = 0 \) be the minimal polynomial of \( g \), which is \textbf{monic} and \textbf{irreducible} over \( \mathbb{Q} \). By Theorem 2, the minimal polynomial \( g(x) \) divides any polynomial with \( g \) as a root. Therefore, \( g(x) \) divides \( f(x) \), giving:
    \[
    f(x) = g(x) h(x)
    \]
    where \( h(x) \) is another polynomial, and both \( g(x) \) and \( h(x) \) have rational coefficients. Since \( f(x) \) has integer coefficients, by Gauss's Lemma, if a monic polynomial with rational coefficients divides a polynomial with integer coefficients, the dividing polynomial must have integer coefficients as well.
    
    Thus, the minimal polynomial \( g(x) \) of the algebraic integer \( g \) must have integer coefficients.
    
\end{proofbox}

\thm{}{Let \( n \) be a positive rational integer, and \( g \) a complex number. Suppose we have a system of \( n \) equations involving complex numbers \( \theta_1, \theta_2, \dots, \theta_n \), not all zero, given by:
\[
g \theta_j = a_{j,1} \theta_1 + a_{j,2} \theta_2 + \dots + a_{j,n} \theta_n, \quad j = 1, 2, \dots, n
\]
where \( a_{j,i} \) are rational numbers. Then:
\begin{enumerate}
    \item \( g \) is an algebraic number.
    \item If \( a_{j,i} \) are rational integers, \( g \) is an algebraic integer.
\end{enumerate}
}

\thm{}{If $\alpha$ and $\beta$ are 
algebraic numbers, then so are $\alpha + \beta$ and $\alpha \beta$. If 
$\alpha$ and $\beta$ are algebraic integers, then so are $\alpha + \beta$ and $\alpha \beta$.}

\section{Ring Theory}
\subsection*{Example 1: The Ring of Integers \(\mathbb{Z}\)}
The set of integers \(\mathbb{Z}\) has two operations: addition and multiplication.
\begin{itemize}
    \item \((\mathbb{Z}, +)\) is an abelian group.
    \item \((\mathbb{Z}, \times)\) is not a group since there is no multiplicative inverse for every element. However, a multiplicative inverse is not required for a set to be a ring.
\end{itemize}

\subsection*{Example 2: The Field of Rational Numbers \(\mathbb{Q}\)}
The set \(\mathbb{Q}\) of rational numbers has two operations: addition and multiplication.
\begin{itemize}
    \item \((\mathbb{Q}, +)\) is an abelian group.
    \item \((\mathbb{Q}, \times)\) is not a group, but \((\mathbb{Q} \setminus \{0\}, \times)\) forms an abelian group.
\end{itemize}

Similarly, the sets \(\mathbb{R}\) (real numbers) and \(\mathbb{C}\) (complex numbers) also form rings under addition and multiplication.

\subsection*{Example 3: The Gaussian Integers \(\mathbb{Z}[i]\)}
Consider \(\mathbb{Z}[i] = \{a + bi \mid a, b \in \mathbb{Z}\}\), where \(i\) is the imaginary unit, i.e., \(i^2 = -1\).
\begin{itemize}
    \item \(1 \in \mathbb{Z}[i]\), and for any integer \(n \in \mathbb{Z}\), \(n \in \mathbb{Z}[i]\).
    \item \(\mathbb{Z}[i] \subseteq \mathbb{C}\), and it is closed under addition:
    \[
    (a + bi) + (c + di) = (a + c) + (b + d)i,
    \]
    where \(a + bi \in \mathbb{Z}[i]\) and \(c + di \in \mathbb{Z}[i]\).
    \item It is easy to verify that \(\mathbb{Z}[i]\) is an abelian group under addition and is a subgroup of \((\mathbb{C}, +)\).
    \item \(\mathbb{Z}[i]\) is closed under multiplication as well:
    \[
    (a + bi)(c + di) = (ac - bd) + (ad + bc)i,
    \]
    and both terms are in \(\mathbb{Z}[i]\).
\end{itemize}
Thus, \(\mathbb{Z}[i]\) is a ring under addition and multiplication.

\subsection*{Example 4: A Non-Ring Set}
Consider the set \(A = \left\{ a + \frac{b}{2} \mid a, b \in \mathbb{Z} \right\}\) (where \(1/2\) replaces \(i\)). Note:
\begin{itemize}
    \item \(\frac{1}{2} \in A\), but \(\frac{1}{2} \times \frac{1}{2} = \frac{1}{4} \notin A\).
\end{itemize}
Therefore, \(A\) is not closed under multiplication, and hence it is not a ring.

\defn{Ring}{A ring \(R\) is a set with two operations, denoted by \(+\) (addition) and \(\times\) (multiplication), satisfying the following properties:
\begin{enumerate}
    \item \((R, +)\) is an abelian group.
    \item Multiplication is commutative, associative, and contains an identity element.
    \item Addition and multiplication are distributive over each other, i.e., \(\forall a, b, c \in R\):
    \[
    (a + b)c = ac + bc \quad \text{and} \quad a(b + c) = ab + ac.
    \]
\end{enumerate}}

Examples: The sets \(\mathbb{Z}, \mathbb{Q}, \mathbb{R}, \mathbb{C}, \mathbb{Z}[i]\) are all rings. Additionally, the distributive property holds for \(\mathbb{C}\), and thus it also holds for the sets \(\mathbb{Z} \subseteq \mathbb{Z}[i] \subseteq \mathbb{C}\), and similarly for \(\mathbb{Z} \subseteq \mathbb{Q} \subseteq \mathbb{R} \subseteq \mathbb{C}\).

Distribtuive property holds for $\mathbb{C}$ so it also holds 
for other sets above:
$\mathbb{Z} \subseteq Z[i] \subseteq \mathbb{C}$.\\\\
$\mathbb{Z} \subseteq \mathbb{Q} \subseteq \mathbb{R} \subseteq \mathbb{C}$.\\\\



\defn{Subring}{Let \(R\) be a ring. A subset \(S\) of \(R\) is called a \textbf{subring} of \(R\) if it satisfies the following conditions:
\begin{itemize}
    \item It is closed under addition and multiplication.
    \item It is a subgroup of \((R, +)\).
    \item It contains the multiplicative identity \(1\).
\end{itemize}}

$\mathbb{Z}$, $\mathbb{Q}$, $\mathbb{R}$,$Z[i]$ are subrings of $\mathbb{C}$.\\\\


\rmk{It is possible to define rings wothout asking for multiplication to be 
commutative. They are called non-commutative rings. For example, the set of
matrix rings:  ex: $3 \times 3$ square matrices with real entries.}

\rmk{Rings can also be defined by not asking for multiplicative identity. ex: $R = 2Z =$ \{ even integers \} does not have $1$.}\\\\

\textbf{More Examples of Rings}
\begin{enumerate}
    \item \textbf{Zero Ring:} Let $R = \{0\}$. In this ring, the only element is $0$, and here $0 = 1$. This is a trivial example of a ring.

    \item \(\mathbb{Z}\) and \(\mathbb{Z}/3\mathbb{Z}\): Consider the integers \(\mathbb{Z}\). The set \(3\mathbb{Z}\) (multiples of 3) is a subgroup of \((\mathbb{Z}, +)\). Now consider the quotient group:
    \[
    \mathbb{Z}/3\mathbb{Z} = \{0, 1, 2\}.
    \]
    More generally, for any \(n \geq 1\), \(\mathbb{Z}/n\mathbb{Z}\) is a ring. If \(n > 0\), the number of elements in \(\mathbb{Z}/n\mathbb{Z}\) is \(n\).
    
    \begin{rmk}
        For \(n \geq 2\), \(\mathbb{Z}/n\mathbb{Z}\) is not a subring of \(\mathbb{C}\).
    \end{rmk}

    \item \textbf{Continuous Functions:} Let \(R = \{f: \mathbb{R} \to \mathbb{R} \mid f \text{ is continuous}\}\). This set forms a ring under pointwise addition and multiplication of functions. There is a well-defined ring structure on this set.
\end{enumerate}


\section{Field}

\defn{Field}{A \textbf{field} \( F \) is a set equipped with two operations: addition (\(+\)) and multiplication (\(\times\)), such that the following properties are satisfied:

\begin{enumerate}
    \item \textbf{Additive Group:} 
    \[
    (F, +) \text{ is an abelian group}.
    \]
    This means:
    \begin{itemize}
        \item For all \( a, b \in F \), \( a + b \in F \) (closure under addition).
        \item There exists an element \( 0 \in F \) such that \( a + 0 = a \) for all \( a \in F \) (additive identity).
        \item For every \( a \in F \), there exists \( -a \in F \) such that \( a + (-a) = 0 \) (additive inverse).
        \item Addition is associative: \( (a + b) + c = a + (b + c) \) for all \( a, b, c \in F \).
        \item Addition is commutative: \( a + b = b + a \) for all \( a, b \in F \).
    \end{itemize}

    \item \textbf{Multiplicative Group:} 
    The set \( F \setminus \{0\} \) (i.e., all non-zero elements of \( F \)) is an abelian group under multiplication:
    \begin{itemize}
        \item For all \( a, b \in F \setminus \{0\} \), \( a \times b \in F \setminus \{0\} \) (closure under multiplication).
        \item There exists an element \( 1 \in F \) such that \( a \times 1 = a \) for all \( a \in F \) (multiplicative identity).
        \item For every \( a \in F \setminus \{0\} \), there exists \( a^{-1} \in F \) such that \( a \times a^{-1} = 1 \) (multiplicative inverse).
        \item Multiplication is associative: \( (a \times b) \times c = a \times (b \times c) \) for all \( a, b, c \in F \).
        \item Multiplication is commutative: \( a \times b = b \times a \) for all \( a, b \in F \setminus \{0\} \).
    \end{itemize}

    \item \textbf{Distributive Property:} 
    Addition and multiplication are distributive over each other. For all \( a, b, c \in F \):
    \[
    a \times (b + c) = a \times b + a \times c \quad \text{and} \quad (a + b) \times c = a \times c + b \times c.
    \]
\end{enumerate}}

\textbf{Key Differences Between Fields and Rings}
\begin{itemize}
    \item In a \textbf{field}, every non-zero element has a \textbf{multiplicative inverse}. In a \textbf{ring}, this is not required. For example, in the ring of integers \( \mathbb{Z} \), only \( 1 \) and \( -1 \) have multiplicative inverses, while in a field like \( \mathbb{Q} \) (the rational numbers), every non-zero element has a multiplicative inverse.
    \item Multiplication in a \textbf{field} is always \textbf{commutative}, whereas rings can be either commutative or non-commutative.
\end{itemize}

\textbf{Examples of Fields}

\begin{enumerate}
    \item \textbf{The Rational Numbers \(\mathbb{Q}\):} Every non-zero rational number has a multiplicative inverse, and all field properties are satisfied.
   
    \item \textbf{The Real Numbers \(\mathbb{R}\):} The set of real numbers is a field under the usual addition and multiplication.
   
    \item \textbf{The Complex Numbers \(\mathbb{C}\):} The complex numbers form a field under addition and multiplication, where every non-zero complex number has a multiplicative inverse.
   
    \item \textbf{Finite Fields \(\mathbb{Z}/p\mathbb{Z}\):} For a prime \( p \), the set \(\mathbb{Z}/p\mathbb{Z}\) (integers modulo \(p\)) forms a field. In this case, every non-zero element has a multiplicative inverse modulo \( p \). For example, \(\mathbb{Z}/5\mathbb{Z} = \{0, 1, 2, 3, 4\}\) is a field.
\end{enumerate}

\textbf{Non-Examples of Fields}
\begin{itemize}
    \item \textbf{The Integers \(\mathbb{Z}\):} While \(\mathbb{Z}\) is a ring, it is not a field because most elements (other than \(1\) and \(-1\)) do not have a multiplicative inverse in \(\mathbb{Z}\).
\end{itemize}

\thm{9.13}{The set of all algebraic numbers forms a field. The set of all
algebraic integers forms a ring.}

\begin{proofbox}
    We begin by recalling the definitions of a \emph{field} and a \emph{ring}.

    \subsection*{Field Properties}
    A field satisfies the following conditions:
    \begin{enumerate}
        \item Closure under addition and multiplication: If \( a \) and \( b \) are elements of the field, then \( a + b \) and \( a \cdot b \) are also in the field.
        \item Associativity of addition and multiplication: For any \( a, b, c \) in the field, \( (a + b) + c = a + (b + c) \) and \( (a \cdot b) \cdot c = a \cdot (b \cdot c) \).
        \item Commutativity of addition and multiplication: For any \( a, b \) in the field, \( a + b = b + a \) and \( a \cdot b = b \cdot a \).
        \item Additive identity: There exists an element \( 0 \) such that for any \( a \), \( a + 0 = a \).
        \item Multiplicative identity: There exists an element \( 1 \) such that for any \( a \), \( a \cdot 1 = a \).
        \item Additive inverses: For every element \( a \), there exists an element \( -a \) such that \( a + (-a) = 0 \).
        \item Multiplicative inverses: For every non-zero element \( a \), there exists an element \( a^{-1} \) such that \( a \cdot a^{-1} = 1 \).
        \item Distributive property: For all \( a, b, c \) in the field, \( a \cdot (b + c) = a \cdot b + a \cdot c \).
    \end{enumerate}
    
    \subsection*{Algebraic Numbers Form a Field}
    Let us now show that the set of all algebraic numbers forms a field. Algebraic numbers are complex numbers that satisfy polynomial equations with rational coefficients. We verify that algebraic numbers satisfy the conditions for a field:
    
    \begin{itemize}
        \item \textbf{Closure under addition and multiplication}: The sum and product of two algebraic numbers is also an algebraic number. For example, \( \sqrt{2} + \sqrt{3} \) is an algebraic number, and \( \sqrt{2} \cdot \sqrt{3} = \sqrt{6} \) is also an algebraic number.
        
        \item \textbf{Associativity}: Algebraic numbers inherit the associative properties of addition and multiplication from complex numbers.
        
        \item \textbf{Commutativity}: Addition and multiplication of algebraic numbers are commutative because complex numbers are commutative.
        
        \item \textbf{Additive identity}: The number \( 0 \) is an algebraic number because it satisfies the polynomial equation \( x = 0 \), which has rational coefficients.
        
        \item \textbf{Multiplicative identity}: The number \( 1 \) is an algebraic number because it satisfies the polynomial equation \( x - 1 = 0 \), which has rational coefficients.
        
        \item \textbf{Additive inverse}: If \( \alpha \) is an algebraic number, its additive inverse \( -\alpha \) is also algebraic. For example, if \( \alpha \) satisfies a polynomial, then \( -\alpha \) satisfies the same equation with appropriate sign changes.
        
        \item \textbf{Multiplicative inverse}: If \( \alpha \neq 0 \) is an algebraic number, its multiplicative inverse \( \alpha^{-1} \) is also algebraic. For example, if \( \alpha \) satisfies a polynomial equation, then \( \alpha^{-1} \) satisfies a polynomial equation constructed from it. For instance, \( 2 \) has an inverse \( 1/2 \), which satisfies \( 2x - 1 = 0 \).
        
        \item \textbf{Distributive property}: Algebraic numbers satisfy the distributive property since complex numbers satisfy the distributive property.
    \end{itemize}
    
    Since all the conditions for a field are satisfied, the set of algebraic numbers forms a \textbf{field}.
    
    \subsection*{Ring Properties}
    A ring satisfies the following conditions:
    \begin{enumerate}
        \item Closure under addition and multiplication.
        \item Associativity of addition and multiplication.
        \item Additive identity.
        \item Additive inverse.
        \item Distributive property.
    \end{enumerate}
    Note that a ring does not require the existence of a multiplicative inverse.
    
    \subsection*{Algebraic Integers Form a Ring}
    Now, consider the set of all algebraic integers, which are algebraic numbers that satisfy monic polynomial equations with integer coefficients. We check the conditions for a ring:
    
    \begin{itemize}
        \item \textbf{Closure under addition and multiplication}: The sum and product of two algebraic integers are also algebraic integers. For example, \( \sqrt{2} \cdot \sqrt{2} = 2 \) is an algebraic integer because it satisfies \( x - 2 = 0 \).
        
        \item \textbf{Associativity}: Algebraic integers inherit the associative properties of addition and multiplication from complex numbers.
        
        \item \textbf{Additive identity}: The number \( 0 \) is an algebraic integer because it satisfies \( x = 0 \).
        
        \item \textbf{Additive inverse}: If \( \alpha \) is an algebraic integer, then \( -\alpha \) is also an algebraic integer. For example, if \( \alpha = \sqrt{2} \), then \( -\sqrt{2} \) satisfies the same equation \( x^2 - 2 = 0 \).
        
        \item \textbf{Distributive property}: Algebraic integers satisfy the distributive property since complex numbers do.
    \end{itemize}
    
    However, algebraic integers do not necessarily have multiplicative inverses that are also algebraic integers. For example, the inverse of \( 2 \) is \( 1/2 \), which is an algebraic number but not an algebraic integer.
    
    Thus, the set of algebraic integers forms a \textbf{ring}, not a field, because it lacks multiplicative inverses for all elements.
    
\end{proofbox}

\section{Proof of Transcendance of Pi }

\lem{}{Let $f$ be an integer polynomial  and $n$ a positive
integer. \begin{enumerate}
    \item If $F(x) = \frac{x^n}{(n-1)!}f(x)$, then $F(h) \equiv 0 \pmod{n}$
    \item If $G(x) = \frac{x^{n-1}}{(n-1)!}f(x)$, then $G(h) \equiv f(0) \pmod{n}$
\end{enumerate}}

\lem{}{For any polynomial $f(x) = \sum_{n = 0}^{m} a_nx^n$, if we let 
$f^{*}(x) = \sum_{n = 0}^{m} a_nx^{n}\epsilon_n(x)$, then $e^{x}f(h) = f(x+h) + e^{|x|}f^{*}(x)$}

\textbf{Step 1:} Suppose $\pi$ is algebraic, so 
$f(\pi) = 0$ for some polynomial with integer coefficients, where
$f(x) = b_0 + b_1x + b_2x^2 + \ldots + b_kx^k$.\\\\

\medskip

Notice $i\pi$ is then algebraic because if $g(x) = f(ix)f(-ix)$, then $g(i\pi) = f(-\pi)f(\pi)$, 
but $f(\pi) = 0$, so $g(i\pi) = 0$.

\medskip

Additionally, observe that $\bar{g(x)} = \overline{f(ix)}\overline{f(-ix)} = f(\bar{ix})f(\bar{-ix}) = f(-ix)f(ix) = g(x)$, so $g(x)$ has real coefficients.

\medskip

Therefore, $i\pi$ is algebraic and $g(x)$ has real coefficients.

Renaming the varaibles, we  can therefore deduce an integral 
polynomial equa satisfied by $\pi i$: \[c_0 + c_1x + c_2x^2 + \ldots + c_mx^m = 0 \tag{4}\] for 
some integers $c_0, c_1, \cdots$.

By the Fundamental Theorem of Algebra this equation has m roots, call them 
$\omega_1, \omega_2, \ldots, \omega_m$ including $\pi i$. Focusing on 
the latter, by Euler formula, \[e^{\pi i} = cos \pi + i sin \pi = -1 + 0i \]
\[ 1 + e^{\pi i} = 0 \]
\[ e^0 + e^{\pi i} = 0 \]

For the other roots as well, we  have $(e^0 + e^{\omega_1}) \cdot (e^0 + e^{\omega_2}) \cdots (e^0 + e^{\omega_m}) = 0$, 
since at least one factor (the one corresponding to $\pi i$) is zero.
\[ e^0 + (e^{\omega_1} + e^{\omega_2} + \ldots + e^{\omega_m}) + (e^{\omega_1}e^{\omega_2} + e^{\omega_1}e^{\omega_3} + \ldots + e^{\omega_{m-1}}e^{\omega_m}) + \ldots + (e^{\omega_1}e^{\omega_2} \cdots e^{\omega_m}) = 0 \]
\[ e^0 + (e^{\omega_1} + e^{\omega_2} + \ldots + e^{\omega_m}) + (e^{\omega_1 + \omega_2} + e^{\omega_1 + \omega_3} + \ldots + e^{\omega_{m-1} + \omega_m}) + \ldots + (e^{\omega_1 + \omega_2 + \ldots + \omega_m}) = 0 \]

Note that each term in the above expression corresponds to one of the $2^m$ subsets of the set of roots
$\{\omega_1, \omega_2, \ldots, \omega_m\}$, and that each exponent is a symmetric integral polynomial of those
roots. Renaming the exponents, $\alpha_1, \alpha_2, \ldots, \alpha_m$, we have
$$ \sum_{i = 1}^{2^m} e^{\alpha_i} = 0 $$

The proof will amount to showing that the left side of this equation equals a nonzero integer plus a proper
fraction, and so cannot equal zero, giving us the contradiction that we sought.
Recall that $\alpha_1 = 0$ and note that some of the pther $\alpha_i$  could 
conveincably vanish as well (not all of them, since the sum of all the roots is not zero).
We now re-index the $\alpha_i$ so that the first $n$ of them are non vanishing.
\[ \sum_{i = 1}^{n} e^{\alpha_i} + \sum_{i = n+1}^{2^m} e^{\alpha_i} = 0 \]
\[ \sum_{i = 1}^{n} e^{\alpha_i}  + q = 0 \text{ setting the integer } q = 2^m - n \tag{5}\]

With special reference to the highest degree coefficient $c_m$ of the polynomial
we now choose any large prime $p$ satisfying \[p > q, p > c_m, p > |(c_m\alpha_1)(c_m\alpha_2) \cdots (c_m\alpha_n)|\]
and consider the polynomial \[ \phi(x) = \frac{c_m^{p-1}}{(p-1)!}x^{p-1}[ c_m^n (x - \alpha_1)(x - \alpha_2) \cdots (x - \alpha_n)]^{p} \tag{6} \]
whose degree is $np + p - 1$.

Multiplying En 5 by $\phi(h)$ gives 
\[ \phi(h) \sum_{i = 1}^{n} e^{\alpha_i} + \phi(h)q = 0 \]
\[ \sum_{i = 1}^{n} \phi(h)e^{\alpha_i} + \phi(h)q = 0 \text{ since } \phi(h) \text{ is independent of } i \]
\[ \sum_{i = 1}^{n} [\phi(\alpha_i + h) + e^{|\alpha_i|}\phi^{*}(\alpha_i)] + \phi(h)q = 0 \text{ by Lemma 11} \]
\[ \sum_{i = 1}^{n} \phi(\alpha_i + h) + \sum_{i = 1}^{n} \phi^{*} (\alpha_i)e^{|\alpha_i|} + \phi(h)q = 0 \]
\[ s_1 + s_2 + s_3 = 0 \text{ by way of abbrevation} \tag{7}\]\\\\

(1) \textbf{We show that }$\mathbf{s_1}$ \textbf{is an integer multiple of chosen prime p}\\\\
To evaluate $s_1$ we start with equation 6, and note that shifting the polynomial $\phi(x)$ by any of 
the displacements $\alpha_i$ creates a net additional factor $x$ i.e. $p$ of them versus $p -1$:

\[ \phi(x + \alpha_i) = \frac{c_m^{p-1}}{(p-1)!}(x + \alpha_i)^{p-1}[c_m^n(x + \alpha_i - \alpha_1)(x + \alpha_i - \alpha_2) \cdots (x + \alpha_i - \alpha_{i - 1})(x)(x + \alpha_i - \alpha_{i + 1}) \cdots (x + \alpha_i - \alpha_n)]^p \]
\[ = \frac{x^p}{(p-1)!}c_m^{p-1}[c_m^n(x + \alpha_i - \alpha_1)(x + \alpha_i - \alpha_2) \cdots (x + \alpha_i - \alpha_{i - 1})(x + \alpha_i - \alpha_{i + 1}) \cdots (x + \alpha_i - \alpha_n)]^p \]
Summing over all $i$ gives
\[ \sum_{i = 1}^{n} \phi(\alpha_i + h) =  \frac{x^p}{(p-1)!} \sum_{i = 1}^{n} c_m^{p-1}[c_m^n(x + \alpha_i - \alpha_1)(x + \alpha_i - \alpha_2) \cdots (x + \alpha_i - \alpha_{i - 1})(x + \alpha_i - \alpha_{i + 1}) \cdots (x + \alpha_i - \alpha_n)]^p \]

The summation portion of the right side is a polynomial in x of degree $(p-1) + (n-1)p = np - 1$.

Multiplying out, and combining like terms, we get:

\[ \sum_{i = 1}^{n} \phi(\alpha_i + h) = \frac{x^p}{(p-1)!}\sum_{j = 1}^{np-1} \beta_jx^j \]

where each coefficient $\beta_j$ is a symmetric integral polynomial of the constants $c_m\alpha_1 c_m\alpha_2 \cdots c_m\alpha_m$. Recall
that each $\alpha_i$ is itself a symmetric integral polynomial of $\omega_1, \omega_2,\cdots,\omega_m$, which are the roots of a polynomial
having integer coefficients, with $c_m$ being the highest-degree coefficient. By Fundamental Theorem of Symmetric Polynomials we can conclude that
$\beta_j$ is an integer for $j = 1, 2, \ldots, np - 1$. This allows us to apply
Lemma 10 to the polynomial $\sum_{i = 1}^{n} \phi(\alpha_i + h)$, which gives us
\[ \sum_{i = 1}^{n} \phi(\alpha_i + h) \equiv 0 \pmod{p} \]
\[s_1 \equiv 0 \pmod{p} \tag{9} \]

(2) \textbf{We show that }$\mathbf{s_2}$ \textbf{is an integer multiple of chosen prime p}\\\\
We will now show that $s_2$ can be made vanishingly small by choosing the prime $p$ to be sufficiently large. To do this, we apply De Moivre's formula and the triangle inequality for complex numbers:
\[
|z_1 z_2| = |z_1| |z_2| \quad \text{and} \quad |x - \alpha_i| \leq |x + \alpha_i| \quad \text{for } i = 1, 2, \dots, n.
\]
Using this inequality, we get the bound:
\[
|(x - \alpha_1)(x - \alpha_2) \dots (x - \alpha_n)| \leq (|x| + |\alpha_1|)(|x| + |\alpha_2|) \dots (|x| + |\alpha_n|)
\]
From Eqn (6), we know:
\[
|\phi(x)| = |\frac{c_m^{p-1}}{(p-1)!} x^{p-1} \left[ c_m^n (x - \alpha_1)(x - \alpha_2) \dots (x - \alpha_n) \right]^p|,
\]
which, using the triangle inequality, gives:
\[
|\phi(x)| \leq \frac{|c_m|^{np + p - 1} |x|^{p-1} [(|x| + |\alpha_1|)(|x| + |\alpha_2|) \dots (|x| + |\alpha_n|)]^p.}{(p-1)!}
\]
As $p$ increases, the factorial term $(p-1)!$ grows faster than any polynomial involving $p$. Thus, for sufficiently large $p$, $\phi(x)$ can be made arbitrarily small:
\[
\phi(x) \to 0 \quad \text{as} \quad p \to \infty.
\]
Similarly, $\phi^*(x)$ can be made arbitrarily small because each term of $\phi^*(x)$ differs from $\phi(x)$ only by the additional factor $\epsilon_n(x)$, which is independent of $p$. Thus:
\[
\phi^*(x) \to 0 \quad \text{as} \quad p \to \infty.
\]
Therefore, the sum $s_2$ defined as:
\[
|s_2| = |\sum_{i=1}^{n} \phi^*(\alpha_i)e^{|\alpha_i|}| < 1 \tag{10}
\]
can also be made arbitrarily small by choosing $p$ sufficiently large. Hence, we conclude that $s_2$ becomes vanishingly small for large $p$.\\

\textbf{Finally, we will show that $s_3$ is an integer not divisible by $p$.}\\\\
To evaluate $s_3$, recall the definition of $\phi(x)$ from Eqn (6):
\[
\phi(x) = \frac{c_m^{p-1}}{(p-1)!} x^{p-1} \left[ c_m^n (x - \alpha_1)(x - \alpha_2) \dots (x - \alpha_n) \right]^p.
\]
\[ \phi(x) = \frac{x^{p-1}}{(p-1)!} c_m^{p-1} [c_m^n (x - \alpha_1)(x - \alpha_2) \dots (x - \alpha_n)]^p \]
Multiplying out and combining like terms, we get:
\[
\phi(x) = \sum_{j=1}^{np} \gamma_j x^j,
\]
where each coefficient $\gamma_j$ is a symmetric integral polynomial in the constants $c_m \alpha_1, c_m \alpha_2, \dots, c_m \alpha_n$. For example, the lowest-degree coefficient is:
\[
\gamma_0 = (-1)^{np} c_m^{p-1} \left[ (c_m \alpha_1)^p (c_m \alpha_2)^p \dots (c_m \alpha_n)^p \right].
\]
By the **Fundamental Theorem of Symmetric Polynomials**, $\gamma_j$ must be an integer for $j = 0, 1, \dots, np$. 

We now apply Lemma 10(b) to Eqn (11), so that $\phi(h)$ is an integer satisfying:
\[
\phi(h) \equiv \gamma_0 \pmod{p},
\]
that is,
\[
\phi(h) \equiv (-1)^{np} c_m^{p-1} \left[ (c_m \alpha_1)^p (c_m \alpha_2)^p \dots (c_m \alpha_n)^p \right] \pmod{p}.
\]
Thus, 
\[
s_3 = q \pmod{p}.
\]
Since we defined $p$ such that $p > q$, $p > c_m$, and $p > |(c_m \alpha_1)(c_m \alpha_2) \dots (c_m \alpha_n)|$, it follows that $p$ does not divide $s_3$. Therefore, $s_3 \not\equiv 0 \pmod{p}$.

Combining this with Eqn (9) implies that neither is $s_1 + s_3$ congruent to 0 modulo $p$. In particular, it cannot be equal to zero:
\[
s_1 + s_3 \neq 0,
\]
and so, in absolute value:
\[
|s_1 + s_3| \geq 1.
\]
Combining this with Eqn (7), we get:
\[
|-s_2| \geq 1 \quad \text{or} \quad |s_2| \geq 1,
\]
which contradicts Eqn (10). 

Thus, our original supposition that $\pi$ is algebraic was false. \textbf{QED.}


\section{Gelfond - Schneider Theorem}

\thm{Gelfond-Schneider Theorem}{If $\alpha$ and $\beta$ are algebraic numbers, with $\alpha \neq 0, 1$, and $\beta$ irrational, then $\alpha^{\beta}$ is transcendental.}

(i) If $l, \beta$ are complex numbers with $l \neq 0$, $\beta \not\in Q$ then at least one of 
$e^{l}$, $\beta$, $e^{\beta l}$ is transcendental.\\\\
(ii) If $\alpha$, $\beta$ are non zero algebraic numners with $\log \alpha$ and 
$\log \beta$ linearly independent over $Q$, then $\log \alpha$ and $\log \beta$ are 
linearly independent over algebraic numbers.\\\\

We shall show that above theorem and the statements (i) and (ii) are equivalent.\\\\

\textbf{ Thm $\Rightarrow$ (i) }\\\\
Take $\alpha = e^{l}$ ($ l \in$ complex numbers), then clearly $\alpha \neq 0$,
$\alpha \neq 1$ because exponential function never takes these values except 
at $l = 0$ but we are excluding that case. 

Now let $\beta$ be any algebraic number that is not rational $(\beta \not\in Q)$.
Then by Gelfond-Schneider theorem, $\alpha^{\beta} = e^{l\beta}$ is transcendental. This means 
that at least one of $e^{l}$, $\beta$, $e^{l\beta}$ is transcendental.\\\\

\textbf{ (i) $\Rightarrow$ (ii) }\\\\
In (ii) we  assume $log \alpha$ and $log \beta$ are linearly  independent, i.e. 
there are no trivial rational numbers $q_1, q_2$ such that $q_1log \alpha + q_2log \beta = 0$.

If $\log \alpha$ and $\log \beta$ are linearly independent then $\frac{\log \alpha}{\log \beta} \not\in Q$.
As if they were, then $\log \alpha = q\log \beta$ for some rational number $q$, which would imply that
$\log \alpha - q\log \beta = 0$, contradicting the linear independence of $\log \alpha$ and $\log \beta$.

Let $l = \log \beta$ and $\beta_0 = \frac{\log \alpha}{\log \beta}$. \\\\
According to (i), since $l$ and $\beta_0$ are complex numbers with $l \neq 0$ and $\beta_0 \not\in Q$, at least one of $e^{l}$, $\beta_0$, $e^{l\beta_0}$ is transcendental.\\\\
This means $\beta_0$ is transcendental because: \\\\
(1.) $e^l = e^{\log \beta} = \beta$ is algebraic, and \\\\
(2.) $e^{l\beta_0} = e^{\log \alpha} = \alpha$ is algebraic.\\\\

As $\beta_0$ is transcendental and therefore there cannot be any non trivial relation 
between $\log \alpha$ and $\log \beta$ over the algebraic numbers. This implies that
$\log \alpha$ and $\log \beta$ are linearly independent over the algebraic numbers.\\\\


(ii) $\Rightarrow$ Thm\\\\

$\beta_0 = e^{\beta \log \alpha}$ i.e. $\alpha^{\beta} = e^{\beta \log \alpha}$.\\\\
By (ii) if $\log \alpha$ and $\log \beta_0$ are linealry dependent over algebraic numbers, then
$\log \alpha$ and $\log \beta$ are linearly dependent over $Q$.\\\\
But by assumption of the thoerem, then $\beta \not \in Q \implies \log \alpha$ and $\log \beta_0$ cannot be 
linearly dependennt over $Q$.\\\\
Therefore if $\beta \not\in Q$ this leads to contradiction because 
$\log \alpha$ and $\log \beta_0$ should be L.D. over $Q$ based on (ii) but they cannot be 
as $\beta \not\in Q$. This contradicts $\alpha^{\beta} = e^{\beta \log \alpha}$ must be transcendental.\\\\
Lang proved a result, similar to statement (i) above.\\
\thm{Lang's Theorem}{Suppose $l_1$, $l_2$, and $l_3$ are linearly independent over the rationals and that $\beta_1$ and
$\beta_2$ are linearly independent over the rationals. Then at least one of the numbers 
$e^{l_i \beta_j}$ (for $i, j = 1,2,3$) is transcendental.}

\textbf{The Brownawell - Waldschmidt result :} The result is similar to Lang's 
theorem, it states that among the numbers that can be formed by taking exponentials of the number 
$e$, (like $e^{e}$, $e^{e^{2}}$, and so on), at least one of them is transcendental.\\\\

\subsection{Baker's Theorem}
\thm{Baker's Theorem}{Let $\alpha_1, \alpha_2, \dots, \alpha_m$ be non-zero algebraic numbers, and suppose that the logarithms $\log \alpha_1, \log \alpha_2, \dots, \log \alpha_m$ are linearly independent over the rationals. Then, these logarithms are also linearly independent over the algebraic numbers.}

\textbf{Explanation:} 

Baker's Theorem is significant because it extends the Gelfond-Schneider Theorem, which dealt with two algebraic numbers $\alpha$ and $\beta$. Baker's result tells us that if the logarithms of multiple algebraic numbers are linearly independent over the rationals, then no non-trivial linear combination of these logarithms with algebraic coefficients can be zero. This implies that many combinations of logarithms of algebraic numbers are \emph{transcendental}, thus expanding the class of known transcendental numbers.\\\\
\subsection{Application of Baker's Theorem: Linear Combinations of Logarithms and Diophantine Approximations}

One of the key applications of results like Baker's Theorem is in studying how "far from zero" a linear combination of logarithms of algebraic numbers can be. Specifically, consider a linear combination of the form:

\[
L = q_1 \log \alpha_1 + q_2 \log \alpha_2 + \dots + q_m \log \alpha_m
\]

where $\alpha_1, \alpha_2, \dots, \alpha_m$ are algebraic numbers, and $q_1, q_2, \dots, q_m$ are coefficients (rational or algebraic). Baker's Theorem tells us that if the logarithms are linearly independent over the rationals, then the combination $L$ cannot be exactly zero unless all the $q_i$ are zero.

The interesting question, however, is: \emph{How close can $L$ be to zero if it is not exactly zero?}

This question is fundamental in understanding \emph{Diophantine approximations}, which deal with how well algebraic numbers (or expressions involving them) can be approximated by rational numbers or other algebraic expressions.


\subsection{Degree and Height of Algebraic Numbers}

To answer the question of how "far from zero" a linear combination like $L$ can be, we introduce two important measures for algebraic numbers: \emph{degree} and \emph{height}.

\defn{Degree of an Algebraic Number}{Let $\alpha$ be an algebraic number. The \emph{degree} of $\alpha$ is the degree of the minimal polynomial $f(x)$ over $\mathbb{Z}$ that $\alpha$ satisfies, i.e., the irreducible polynomial:}
\[
f(x) = a_d x^d + a_{d-1} x^{d-1} + \dots + a_1 x + a_0
\]

where $a_d \neq 0$ and $f(x) \in \mathbb{Z}[x]$. The degree $d$ is the degree of this polynomial.

\defn{Height of an Algebraic Number}{
Let $\alpha$ be an algebraic number that satisfies an irreducible polynomial $f(x)$ over the integers as defined above. The \emph{height} of $\alpha$ is defined as the maximum absolute value of the coefficients of $f(x)$, i.e.,
\[
A = \max_{0 \leq j \leq d} |a_j|
\]

where $a_j$ are the coefficients of the minimal polynomial $f(x)$.}

\textbf{Why Degree and Height Matter:}

The \emph{degree} and \emph{height} of an algebraic number help us quantify how complicated the number is. In the context of Diophantine approximations, these measures allow us to give precise bounds on how close a linear combination of logarithms of algebraic numbers can get to zero.

In particular, Baker's method can be used to give explicit lower bounds on non-zero linear combinations of logarithms, which ensures that such combinations are not too close to zero. This has important implications in areas of number theory where precise approximations are required, such as in solving Diophantine equations.

\subsection{Lower Bound on Linear Combinations of Logarithms}
\thm{Lower Bound on Linear Combinations of Logarithms}{Let $\alpha_1, \dots, \alpha_r$ be non-zero algebraic numbers with degrees at most $d$ and heights at most $A$. Let $\beta_0, \beta_1, \dots, \beta_r$ be algebraic numbers with degrees at most $d$ and heights at most $B > 1$. Suppose that:

\[
\Lambda = \beta_0 + \beta_1 \log \alpha_1 + \dots + \beta_r \log \alpha_r \neq 0.
\]

Then, there exist constants $C = C(r, d) > 0$ and $w = w(r) \geq 1$ such that:
\[
|\Lambda| > B^{-C(\log A)^w}.
\]}

\textbf{Explanation:}\\\\


This theorem gives a lower bound for the absolute value of $\Lambda$, a linear combination of logarithms of algebraic numbers. The key components of the theorem are as follows:

\begin{itemize}
    \item $\alpha_1, \dots, \alpha_r$ are non-zero algebraic numbers with bounded degrees (at most $d$) and heights (at most $A$).
    \item $\beta_0, \beta_1, \dots, \beta_r$ are algebraic coefficients with bounded degrees (at most $d$) and heights (at most $B$).
    \item $\Lambda$ represents a linear combination of the form:
    \[
    \Lambda = \beta_0 + \beta_1 \log \alpha_1 + \dots + \beta_r \log \alpha_r.
    \]
    If $\Lambda \neq 0$, the theorem guarantees that $\Lambda$ cannot be arbitrarily small; it is bounded below by the expression $B^{-C(\log A)^w}$.
\end{itemize}

Recall that the \emph{degree} of an algebraic number $\alpha$ is the degree of its minimal polynomial over $\mathbb{Z}$, and the \emph{height} of $\alpha$ is the maximum absolute value of the coefficients of this minimal polynomial.

The theorem applies to algebraic numbers whose degrees and heights are controlled:
\begin{itemize}
    \item The degrees of the $\alpha_i$ and $\beta_i$ are bounded by $d$.
    \item The heights of the $\alpha_i$ are bounded by $A$, and the heights of the $\beta_i$ are bounded by $B > 1$.
\end{itemize}

The constants $C$ and $w$ depend only on the number of terms in the linear combination $r$ and the degrees of the algebraic numbers $d$. These constants ensure that the lower bound for $|\Lambda|$ remains significant, even as $A$ and $B$ grow.\\\\
Above theorem is a quantitative result that has important applications in Diophantine approximation. It shows that linear combinations of logarithms of algebraic numbers cannot approach zero too closely, unless they are zero. The degree and height of the algebraic numbers involved dictate how small $\Lambda$ can be.

\subsection{Proof of Gelfond-Schneider Theorem}

General outline: \\\\
The general approach to proving the Gelfond-Schneider Theorem relies on a contradiction. Suppose that $\alpha^\beta$ is algebraic. The goal is to deduce that this assumption leads to the conclusion that $\beta \in \mathbb{Q}$, which contradicts the hypothesis that $\beta \notin \mathbb{Q}$.

The proof can be broken down into several key steps:
\begin{itemize}
    \item We begin by assuming that $\alpha^\beta$ is algebraic, and we aim to show that $\beta \in \mathbb{Q}$.
    \item First, we reduce the problem to the special case where both $\alpha > 0$ and $\beta$ are real numbers.
    \item Next, we establish several lemmas that will be used to bound the number of real roots of certain functions involving exponential terms.
    \item These bounds will eventually lead to a contradiction, which will complete the proof.
\end{itemize}

The core of the proof uses properties of polynomials, exponentials, and logarithms of algebraic numbers. It also makes use of Rolle's Theorem, the Maximum Modulus Principle from complex analysis, and some combinatorial arguments.\\\\
\textbf{The Special Case: $\alpha > 0$ and $\beta$ are Real}

We start by considering the special case where $\alpha > 0$ and both $\alpha$ and $\beta$ are real. To establish the result, it suffices to show that if $\alpha^\beta$ is algebraic, then $\beta \in \mathbb{Q}$.

Since $\alpha^\beta$ is algebraic, observe that $\alpha^{s_1 + s_2 \beta}$ is also an algebraic number for all integers $s_1$ and $s_2$. Thus, the behavior of expressions involving $\alpha$ and $\beta$ can be analyzed using properties of logarithms and exponentials.

The strategy is to show that there exist distinct pairs of integers $(s_1, s_2)$ and $(s_1', s_2')$ such that:
\[
s_1 + s_2 \beta = s_1' + s_2' \beta.
\]
This would imply that $\beta$ is a rational number, which contradicts the assumption that $\beta \notin \mathbb{Q}$.

\lem{Lemma 1}{Let $a_1(t), a_2(t), \dots, a_n(t)$ be non-zero polynomials in $\mathbb{R}[t]$ of degrees $d_1, d_2, \dots, d_n$, respectively. Let $w_1, w_2, \dots, w_n$ be distinct real numbers. Then the function:
\[
F(t) = \sum_{j=1}^n a_j(t) e^{w_j t}
\]
has at most $d_1 + d_2 + \dots + d_n + n - 1$ real zeroes (counting multiplicities).
}
\textbf{Lemma Explanation:}\\\\
This lemma provides an upper bound on the number of real roots for a function that is a sum of polynomials multiplied by distinct exponential terms. Each \( a_j(t) \) is a polynomial, and each \( e^{w_j t} \) is an exponential with a distinct real exponent \( w_j \). The lemma tells us that the total number of real roots (where \( F(t) = 0 \)) cannot exceed the sum of the degrees of the polynomials plus \( n - 1 \), where \( n \) is the number of terms in the sum.

The distinct exponents \( w_j \) ensure that the exponential functions grow at different rates, which limits the number of real roots the function can have. This is important in applications where we need to bound the number of real solutions to transcendental equations involving both polynomial and exponential terms.\\\\
\textbf{Example to Illustrate the Lemma:}\\\\
Consider the polynomials:

\[
a_1(t) = t + 1 \quad \text{and} \quad a_2(t) = 2,
\]

and the distinct real exponents \( w_1 = 1 \) and \( w_2 = 2 \). According to the lemma, the function:

\[
F(t) = (t + 1) e^t + 2 e^{2t}
\]

should have at most \( d_1 + d_2 + n - 1 = 1 + 0 + 2 - 1 = 2 \) real roots, where \( d_1 = 1 \) is the degree of \( a_1(t) \), \( d_2 = 0 \) is the degree of \( a_2(t) \), and \( n = 2 \) is the number of terms.

\textbf{Analyzing the roots of \( F(t) = 0 \):}
We can factor out the exponential term \( e^t \) from the expression for \( F(t) \):

\[
F(t) = e^t \left( (t + 1) + 2 e^t \right).
\]

Since \( e^t \) is never zero, we can reduce the equation to solving:

\[
(t + 1) + 2 e^t = 0.
\]

This equation does not have a simple algebraic solution, so we use numerical methods to estimate the real roots.

At \( t = -1 \), we have:

\[
(-1 + 1) + 2 e^{-1} = 0 + \frac{2}{e} > 0.
\]

At \( t = -2 \), we have:

\[
(-2 + 1) + 2 e^{-2} = -1 + \frac{2}{e^2} \approx -1 + 0.27 < 0.
\]

Thus, by the Intermediate Value Theorem, there is a root between \( t = -2 \) and \( t = -1 \).

At \( t = 0 \), we have:

\[
(0 + 1) + 2 e^0 = 1 + 2 = 3.
\]

At \( t = -3 \), we have:

\[
(-3 + 1) + 2 e^{-3} = -2 + \frac{2}{e^3} \approx -2 + 0.1 < 0.
\]

Thus, by the Intermediate Value Theorem again, there is another root between \( t = -3 \) and \( t = -2 \).

\textbf{Conclusion:} 
We found two real roots for the function \( F(t) = (t + 1) e^t + 2 e^{2t} \), which matches the prediction of Lemma 14. According to the lemma, the function could have at most 2 real roots, and that is exactly what we found.

This example illustrates how the lemma provides an upper bound on the number of real roots when combining polynomials and exponential functions with distinct exponents.\\\\
\textbf{Proof of Lemma 1:}\\\\

\begin{proofbox}

We prove Lemma 14 by induction on the total degree of the polynomials involved, defined as:
\[
k = d_1 + d_2 + \dots + d_n + n.
\]

\textbf{Base Case (k = 1):} If $k = 1$, then $n = 1$ and $d_1 = 0$, meaning that $a_1(t)$ is a constant polynomial. In this case, $F(t) = a_1 e^{w_1 t}$, and the lemma easily holds since $F(t)$ has at most one real root.

\textbf{Inductive Step:} Assume that the lemma holds for all cases where $k < \ell$. Now, we must show that it holds when $k = \ell$.

Let $N$ be the number of real roots of $F(t)$. By \textbf{Rolle's Theorem}, the number of real roots of the derivative $F'(t)$ is at least $N - 1$. We now compute the derivative of $F(t)$:
\[
F'(t) = \sum_{j=1}^n \left( a_j'(t) + w_j a_j(t) \right) e^{w_j t}.
\]
Define new polynomials:
\[
b_j(t) = a_j'(t) + w_j a_j(t),
\]
so that:
\[
F'(t) = \sum_{j=1}^n b_j(t) e^{w_j t}.
\]

For $j = 1, 2, \dots, n-1$, the degree of $b_j(t)$ is equal to $d_j$. For $j = n$, since $w_n = 0$, the degree of $b_n(t)$ is one less than the degree of $a_n(t)$.

By the inductive hypothesis, $F'(t)$ has at most $d_1 + d_2 + \dots + d_n + n - 2$ real roots. Therefore, by Rolle's Theorem:
\[
N - 1 \leq d_1 + d_2 + \dots + d_n + n - 2,
\]
which implies:
\[
N \leq d_1 + d_2 + \dots + d_n + n - 1.
\]
Thus, the lemma is proven.\\\\
    
\end{proofbox}


\lem{Lemma 2}{Suppose \( f(z) \) is an analytic function inside the disk \( D = \{ z : |z| < R \} \), and suppose it is continuous on the boundary of the disk \( \{ z : |z| = R \} \). Then, for all \( z \in D \), we have:
\[
|f(z)| \leq |f|_R,
\]
where \( |f|_R \) denotes the maximum value of \( |f(z)| \) on the boundary of the disk \( \{ z : |z| = R \} \).
}

This lemma is a version of the Maximum Modulus Principle, a fundamental result in complex analysis. It tells us that if a function \( f(z) \) is analytic in a region (here, the disk \( D \)) and continuous on the boundary of that region, then the maximum value of \( |f(z)| \) inside the disk occurs on the boundary. In other words, the function cannot have a larger absolute value inside the disk than it does on the boundary.

\lem{Lemma 3: Upper Bound on Determinants of Analytic Functions}{
    Let \( f_1(z), f_2(z), \dots, f_L(z) \) be analytic functions inside the disk \( D = \{ z : |z| < R \} \) and continuous on the boundary \( \{ z : |z| \leq R \} \). Let \( \zeta_1, \dots, \zeta_L \) be points such that \( |\zeta_j| \leq r \) for each \( j \), where \( 1 \leq r \leq R \). 

The determinant \( \Delta \) of the matrix:

\[
\Delta = \det
\begin{pmatrix}
f_1(\zeta_1) & \cdots & f_L(\zeta_1) \\
\vdots & \ddots & \vdots \\
f_1(\zeta_L) & \cdots & f_L(\zeta_L)
\end{pmatrix}
\]

satisfies the bound:

\[
|\Delta| \leq \left( \frac{R}{r} \right)^{-\frac{L(L-1)}{2}} L! \prod_{\lambda=1}^{L} |f_{\lambda}|_R,
\]
where \( |f_{\lambda}|_R \) denotes the maximum value of \( |f_{\lambda}(z)| \) on the boundary of the disk \( |z| = R \).
}

\textbf{Explanation of Lemma 3:}\\\\
This lemma provides an upper bound on the absolute value of the determinant \( \Delta \), which is formed by evaluating a set of analytic functions \( f_1(z), f_2(z), \dots, f_L(z) \) at specific points \( \zeta_1, \dots, \zeta_L \) inside the disk.

The determinant \( \Delta \) measures how "independent" the values of these functions are at the points \( \zeta_1, \dots, \zeta_L \). If the determinant is zero, it means the functions are linearly dependent at those points.

\emph{Bound on \( \Delta \):} The lemma shows that \( |\Delta| \), the absolute value of the determinant, is bounded by the product of the maximum values of the functions on the boundary \( |z| = R \), scaled by the ratio \( \frac{R}{r} \), where \( r \) is the distance of the points \( \zeta_j \) from the origin.\\\\
\textbf{Why This is Important:} 
The determinant \( \Delta \) appears in many applications of transcendental number theory, and bounding its size is crucial for proving results like the Gelfond-Schneider theorem. The lemma uses properties of analytic functions, such as their maximum modulus (Lemma 2), to control the size of \( \Delta \).

In particular, the ratio \( \frac{R}{r} \) reflects how the size of the disk and the location of the points \( \zeta_1, \dots, \zeta_L \) influence the determinant. As the points \( \zeta_j \) approach the boundary (i.e., as \( r \to R \)), the determinant becomes more sensitive to the values of the functions.
Lemma 3 gives an essential tool for controlling the size of determinants involving analytic functions, particularly when the functions are evaluated at points inside a disk. \\\\
\textbf{Proof of Lemma 3:}\\\\
\begin{proofbox}
    
Let \( h(z) \) be the determinant of the \( L \times L \) matrix whose entries are \( f_j(\zeta_i z) \), for \( 1 \leq i, j \leq L \). That is,

\[
h(z) = \det(f_j(\zeta_i z)).
\]

This function \( h(z) \) is analytic inside the disk \( D_0 = \{ z : |z| < R/r \} \) and continuous on the boundary \( |z| = R/r \). Our goal is to bound \( |h(z)| \).\\\\
We begin by expanding \( f_j(\zeta_i z) \) as a power series:
\[
f_j(\zeta_i z) = \sum_{k=0}^{M-1} b_k(j) \zeta_i^k z^k + z^M g_{i,j}(z),
\]
where \( b_k(j) \) are the coefficients from the series expansion, and \( g_{i,j}(z) \) is analytic inside \( D_0 \). Here, \( M = L(L-1)/2 \) is chosen for simplicity.\\\\
Since the determinant is linear in its columns, we can factor out powers of \( z \) in each term. This leads to the expression:
\[
h(z) = z^M \cdot \left( \text{analytic function} \right) + \sum_{\text{distinct } n_1, n_2, \dots, n_L} z^{n_1 + n_2 + \dots + n_L} \cdot \det(\zeta_i^{n_j}).
\]

Notice that the determinant \( \det(\zeta_i^{n_j}) \) is zero if the powers \( n_1, n_2, \dots, n_L \) are not distinct. The smallest sum of the powers is:
\[
n_1 + n_2 + \dots + n_L \geq 0 + 1 + 2 + \dots + (L-1) = \frac{L(L-1)}{2}.
\]
Thus, \( h(z) \) is divisible by \( z^M \), where \( M = \frac{L(L-1)}{2} \).\\\\\\
Since \( h(z) / z^M \) is analytic and continuous on \( D_0 \), we can apply Lemma 2 (Maximum Modulus Principle) to bound the size of \( h(z) \) inside \( D_0 \). Specifically, for any \( w \in D_0 \), we have:
\[
\left| \frac{h(w)}{w^M} \right| \leq \left| \frac{h(z)}{z^M} \right|_{R/r}.
\]
This means that the maximum value of \( |h(w)| \) is controlled by its values on the boundary \( |z| = R/r \).


For \( |z| = R/r \), we have \( |\zeta_i z| \leq R \). Thus, the determinant \( h(z) \) can be bounded by:
\[
|h(z)|_{R/r} \leq L! \prod_{\lambda=1}^{L} |f_\lambda|_R,
\]
where \( |f_\lambda|_R \) is the maximum modulus of \( f_\lambda(z) \) on the boundary \( |z| = R \).


As \( \Delta = h(1) \), we conclude that:
\[
|\Delta| = |h(1)| \leq \left( \frac{r}{R} \right)^M |h(z)|_{R/r} \leq \left( \frac{r}{R} \right)^M L! \prod_{\lambda=1}^{L} |f_\lambda|_R.
\]
This gives the desired bound on \( |\Delta| \), where \( M = \frac{L(L-1)}{2} \), and completes the proof.

\end{proofbox}

\lem{Lemma 4}{Let \( \Delta = \det(\alpha_{i,j})_{L \times L} \), where \( \alpha_{i,j} \) are algebraic numbers. Suppose there exists a positive integer \( T \) such that \( T \alpha_{i,j} \) is an algebraic integer for all \( i, j \in \{1, 2, \dots, L\} \). If \( \Delta \neq 0 \), then there is a conjugate of \( \Delta \) whose absolute value is at least \( T^{-L} \).
}
\begin{proofbox}
    Consider the determinant \( \Delta \) of the matrix \( (\alpha_{i,j}) \). Since \( T \alpha_{i,j} \) is an algebraic integer, the determinant \( T^L \Delta \) is also an algebraic integer. Therefore, all the conjugates of \( T^L \Delta \) are algebraic integers.

At least one of the conjugates of \( T^L \Delta \) must have an absolute value \( \geq 1 \) because the absolute value of an algebraic integer's conjugates cannot be arbitrarily small unless the integer is zero (which is not the case here, since \( \Delta \neq 0 \)).

Thus, one of the conjugates of \( T^L \Delta \) satisfies:
\[
| \text{conjugate of } T^L \Delta | \geq 1.
\]
Dividing by \( T^L \), we find that at least one conjugate of \( \Delta \) satisfies:
\[
| \text{conjugate of } \Delta | \geq T^{-L}.
\]
This completes the proof.
\end{proofbox}

\textbf{Now we walk through the proof of the Gelfond-Schneider Theorem:}\\\\
\begin{proofbox}
   
Let $c$ be a sufficiently large real number (to be specified later). Consider the integers $L_0$, $L_1$, and $S$, where each of them is at least 2. Define $L = (L_0 + 1)(L_1 + 1)$.

We select $L_0$, $L_1$, and $S$ to satisfy the following inequalities:
\[
c L_0 \log S \leq L, \quad c L_1 S \leq L, \quad L \leq (2S - 1)^2
\]
For example, if $S$ is large, we can take:
\[
L_0 = \lfloor S \log S \rfloor, \quad L_1 = \lfloor \frac{S}{\log S} \rfloor
\]
(We could also take $c = \log \log S$.)

Now, consider a matrix $M$ described as follows:
- Take an arrangement of the integral pairs $(s_1(i), s_2(i))$ where $|s_1| < S$ and $|s_2| < S$, for a total of $(2S - 1)^2$ pairs.
- Similarly, arrange pairs $(u(j), v(j))$ for $1 \leq j \leq L$ where $0 \leq u \leq L_0$ and $0 \leq v \leq L_1$.

Define the matrix $M$ as:
\[
M(i,j) = \left( s_1(i) + s_2(i) \beta \right)^{u(j)} \alpha^{\left( s_1(i) + s_2(i) \beta \right) v(j)}
\]
where $M$ is a $(2S - 1)^2 \times L$ matrix. 

We now outline the main steps for proving the result:
\begin{itemize}
    \item[(i)] Consider the determinant $\Delta$ of an arbitrary $L \times L$ submatrix of $M$.
    \item[(ii)] Use Lemma 3 to obtain an upper bound $B_1$ for $\log |\Delta|$.
    \item[(iii)] Use Lemma 4 to argue that if $\Delta \neq 0$, then $\Delta$ has an absolute value $\geq B_2$ with $B_2 > B_1$. (We assume this for contradiction.)
    \item[(iv)] Conclude that $\Delta = 0$ and hence the rank of $M$ is less than $L$.
    \item[(v)] Use a linear combination of the columns of $M$ to form a function $F(t)$ as in Lemma 1, with fewer than $L$ roots, such that $F(s_1(i) + s_2(i)\beta) = 0$ for $1 \leq i \leq L$.
    \item[(vi)] Conclude that $\beta$ is rational.
\end{itemize}

Now, we define the functions $f_j(z)$ for each column $j$ of the matrix:
\[
f_j(z) = z^{u(j)} \alpha^{v(j) z} = z^{u(j)} \exp \left( v(j) z \log \alpha \right)
\]
where $z = s_1(i) + s_2(i) \beta$. Note that $u(j)$ is a non-negative integer and $\alpha^{v(j) z} = \exp(v(j) z \log \alpha)$. We fix $\log \alpha$ so that it is real. Thus, each $f_j(z)$ is an entire function.

To proceed, we need an upper bound on $|f_j(z)|$. Using the fact that:
\[
|e^{z_1 z_2}| = e^{\text{Re}(z_1 z_2)} \leq e^{|z_1 z_2|} = e^{|z_1||z_2|}
\]
for all complex numbers $z_1$ and $z_2$, we obtain that:
\[
|f_j|_R \leq R^{u(j)} e^{v(j) R |\log \alpha|}
\]
for any $R > 0$.

Now, apply Lemma 3 with $r = S(1 + |\beta|)$ and $R = e^2 r$. For some constant $c_1 > 0$, we obtain the bound:
\[
\log |\Delta| \leq -L(L - 1) + \log L! + L \max_{1 \leq j \leq L} \{ \log |f_j|_R \}
\]
Substitute the upper bound for $|f_j|_R$:
\[
\log |\Delta| \leq -L(L - 1) + L \log L + L L_0 \log R + L L_1 R |\log \alpha|
\]
Simplifying further:
\[
\log |\Delta| \leq -L^2 + c_1 (L L_0 \log S + L L_1 S)
\]
The constant $c_1$ is independent of $c$. Therefore, if $c$ is sufficiently large (for example, $c \geq 4c_1$), then we conclude:
\[
\log |\Delta| \leq -\frac{L^2}{2}
\]

Suppose now that $T_0$ is a positive rational integer for which $T_0\alpha$, $T_0\beta$, and $T_0\alpha^{\beta}$ are all algebraic integers. Then $T = (T_0)^{L_0 + 2S L_1}$ has the property that $T$ times any element of $M$ (and hence $T$ times any element of the matrix describing $\Delta$) is an algebraic integer.

Therefore, by Lemma 4, if $\Delta \neq 0$, then there is a conjugate of $\Delta$ with absolute value at least:
\[
|\text{conjugate of } \Delta| \geq T^{-L} = (T_0)^{-L(L_0 + 2S L_1)}.
\]

It is reasonable to expect a similar inequality might hold for $|\Delta|$ itself (rather than for the absolute value of a conjugate of $\Delta$). In fact, it can be shown (and will be shown later) that if $\Delta \neq 0$, then there is a constant $c_2$ (independent of $c$) for which:
\[
\log |\Delta| \geq -c_2(LL_0 \log S + SL_1L). \tag{10}
\]

By using our upper bound for $\log |\Delta|$ above, we see that for $c$ sufficiently large (say, $c \geq 8c_2$ will do), we obtain that $\Delta = 0$.

Since $\Delta = \det(f_j(\zeta_i))$ as defined above, we get that the columns of $(f_j(\zeta_i))$ must be linearly dependent (over the reals). In other words, there exist real numbers $b_j$, not all zero, such that:
\[
\sum_{j=1}^{L} b_j f_j(\zeta_i) = 0 \quad \text{for } 1 \leq i \leq L.
\]

By considering a particular ordering of the $(u(j), v(j))$, we deduce that:
\[
\sum_{v=0}^{L_1} \sum_{u=0}^{L_0} b_{(L_0 + 1)v + u + 1} \zeta_i^u \alpha^v = 0 \quad \text{for } 1 \leq i \leq L.
\]
But:
\[
\sum_{v=0}^{L_1} \sum_{u=0}^{L_0} b_{(L_0 + 1)v + u + 1} \zeta_i^u \alpha^v = \sum_{v=0}^{L_1} a_v(t) e^{w_v t}
\]
where $a_v(t) = \sum_{u=0}^{L_0} b_{(L_0 + 1)v + u + 1} t^u$, $w_v = v \log \alpha$, and $t = \zeta_i = s_1(i) + s_2(i)\beta$.

Each of the $L$ values of $\zeta_i$ is a root of $\sum_{v=0}^{L_1} a_v(t) e^{w_v t} = 0$. Since some $b_j \neq 0$, we deduce from Lemma 1 that there are at most $L_0(L_1 + 1) + (L_1 + 1) - 1 < L$ distinct real roots. Therefore, two roots $\zeta_i$ must be the same, and we can conclude that:
\[
s_1(i) + s_2(i) \beta = s_1(i') + s_2(i') \beta
\]
for some $i, i'$ with $1 \leq i < i' \leq L$.

On the other hand, the pairs $(s_1(i), s_2(i))$ and $(s_1(i'), s_2(i'))$ are necessarily distinct, so we can conclude that $\beta$ is rational, completing the proof of Lemma 1.

\end{proofbox}
\section{Algebraic Number Fields}

Let $\xi$ be an algebraic number. Then,
\[
\mathbb{Q}(\xi) = \left\{ \frac{f(\xi)}{g(\xi)} : f(x), g(x) \in \mathbb{Q}[x], g(\xi) \neq 0 \right\}.
\]

\thm{}{
Let $\xi$ be an algebraic number of degree $n$ over $\mathbb{Q}$. Then the degree of the field $\mathbb{Q}(\xi)$ over $\mathbb{Q}$ is at most $n$. Moreover, any element of $\mathbb{Q}(\xi)$ can be uniquely written in the form
\[
a_0 + a_1 \xi + a_2 \xi^2 + \dots + a_{n-1} \xi^{n-1}
\]
where $a_0, a_1, \dots, a_{n-1} \in \mathbb{Q}$.
}

\begin{example}
    Let \(\xi = \sqrt{2}\), an algebraic number of degree \(2\) over \(\mathbb{Q}\) as it is a root of the irreducible polynomial \(x^2 - 2\). According to the theorem, any element \(\alpha \in \mathbb{Q}(\xi)\) can be uniquely expressed in the form
    \[
    \alpha = a_0 + a_1 \xi
    \]
    where \(a_0, a_1 \in \mathbb{Q}\).

    For instance, consider \(\alpha = \frac{3 + 5\sqrt{2}}{4}\). We can rewrite this as
    \[
    \alpha = \frac{3}{4} + \frac{5}{4}\sqrt{2},
    \]
    with \(a_0 = \frac{3}{4}\) and \(a_1 = \frac{5}{4}\), both in \(\mathbb{Q}\). This shows that every element in \(\mathbb{Q}(\sqrt{2})\) can indeed be written in the form \(a_0 + a_1 \xi\), as required.
\end{example}

\begin{proof}
    Suppose $\xi$ satisfies an irreducible polynomial $h(x) \in \mathbb{Q}[x]$ of degree $n$ given by
    \[
    h(x) = x^n + b_1 x^{n-1} + \dots + b_n,
    \]
    with $b_i \in \mathbb{Q}$. Since $\deg(\xi) = n$, $h(x)$ is the minimal polynomial of $\xi$ over $\mathbb{Q}$.

    Let $\alpha \in \mathbb{Q}(\xi)$. Then $\alpha$ can be expressed as
    \[
    \alpha = \frac{f(\xi)}{g(\xi)},
    \]
    where $f(x), g(x) \in \mathbb{Q}[x]$ and $g(\xi) \neq 0$.

    Since $\gcd(g(x), h(x)) = 1$, there exist polynomials $G(x), H(x) \in \mathbb{Q}[x]$ such that
    \[
    G(x)g(x) + H(x)h(x) = 1.
    \]
    Substituting $x = \xi$, we find that $G(\xi)g(\xi) = 1/g(\xi)$, and thus,
    \[
    \alpha = f(\xi)G(\xi).
    \]
    Therefore, $\alpha$ is a polynomial in $\xi$ over $\mathbb{Q}$, say $\alpha = s(\xi)$, where $s(x) \in \mathbb{Q}[x]$.

    We can divide $s(x)$ by $h(x)$, obtaining
    \[
    s(x) = q(x)h(x) + r(x),
    \]
    where $r(x) = 0$ or $\deg(r(x)) < n$. Then,
    \[
    \alpha = s(\xi) = r(\xi),
    \]
    so $\alpha = a_0 + a_1 \xi + \dots + a_{n-1} \xi^{n-1}$, with $a_i \in \mathbb{Q}$.

    Finally, to prove uniqueness, assume
    \[
    \alpha = a_0' + a_1' \xi + \dots + a_{n-1}' \xi^{n-1}.
    \]
    If \(a_i \neq a_i'\) for some \(i\), then \(\xi\) satisfies a non-zero polynomial of degree less than \(n\), a contradiction. Hence, the expression is unique.
\end{proof}

\begin{example}
If $K = \mathbb{Q}(2^{1/3})$, then $2^{1/3}$ is a root of the irreducible polynomial $x^3 - 2$. Thus, any element in $K$ can be written as
\[
a_0 + a_1 2^{1/3} + a_2 2^{2/3}
\]
where $a_0, a_1, a_2 \in \mathbb{Q}$.
\end{example}

\section{Quadratic Fields}

\defn{Quadratic Field}{
A field $K = \mathbb{Q}(\alpha)$, where $\alpha$ is an algebraic number of degree 2, is called a quadratic field.}

\begin{example}
    The field \(\mathbb{Q}(\sqrt{5}) = \{a + b\sqrt{5} : a, b \in \mathbb{Q}\}\) is a quadratic field since \(\sqrt{5}\) is a root of the irreducible polynomial \(x^2 - 5\).

    Similarly, consider \(\mathbb{Q}\left(\frac{2 + \sqrt{7}}{2}\right)\). Let \(\alpha = \frac{2 + \sqrt{7}}{2}\). Then, \(2\alpha - 2 = \sqrt{7}\), so \(\alpha\) is a root of the irreducible polynomial \(x^2 - 2x - 2\). Thus, \(\mathbb{Q}\left(\frac{2 + \sqrt{7}}{2}\right)\) is a quadratic field.

    Note:
    \[
    \mathbb{Q}\left(\frac{2 + \sqrt{7}}{2}\right) = \mathbb{Q}(\sqrt{7}),
    \]
    \[
    \mathbb{Q}\left(\frac{3 + \sqrt{-3/7}}{5}\right) = Q(\sqrt{\frac{-3}{7}}) = Q(\sqrt{\frac{ -21}{49}}) = Q(\frac{1}{7} \sqrt{-21}) = \mathbb{Q}\left(\sqrt{-21}\right),
    \]
    \[
    \mathbb{Q}(\sqrt{20}) = Q(2\sqrt{5}) = \mathbb{Q}(\sqrt{5}).
    \]
\end{example}

\prop{
Let $K = \mathbb{Q}(\alpha)$ be a quadratic field, where $\alpha$ is an algebraic number of degree 2. Then $K = \mathbb{Q}(\sqrt{m})$ for some square-free integer $m \neq 1$.}

\begin{proof}
    Suppose $\alpha$ satisfies a polynomial \(ax^2 + bx + c = 0\) with \(a, b, c \in \mathbb{Z}\). Then,
    \[
    \alpha = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a},
    \]
    where \(b^2 - 4ac\) is not a perfect square. Thus, \(\mathbb{Q}(\alpha) = \mathbb{Q}(\sqrt{m})\), where \(m\) is a square-free integer.

\end{proof}
    \clm{}{
    Given a quadratic field, there is a unique square-free integer \(m \neq 1\) such that the field is \(\mathbb{Q}(\sqrt{m})\).
    }
    
    \begin{proof}
        Suppose \( Q(\sqrt{m}) = Q(\sqrt{n}) \) for two integers \( m \) and \( n \). This implies that \( \sqrt{m} \) can be expressed in terms of \( \sqrt{n} \). Therefore, there exist rational numbers \( a \) and \( b \) such that
        \[
        \sqrt{m} = a + b \sqrt{n}.
        \]
        
        \noindent Squaring both sides of the equation, we get:
        \[
        m = a^2 + 2ab \sqrt{n} + b^2 n.
        \]
        Since \( \sqrt{n} \) is irrational (because \( n \) is square-free and \( n \neq 1 \)), the coefficient of \( \sqrt{n} \) must be zero. Thus, we must have \( 2ab = 0 \).
        
        \noindent \textbf{Case Analysis:}
        \begin{itemize}
            \item \textbf{Case 1:} \( b = 0 \) \\
            If \( b = 0 \), then \( \sqrt{m} = a \), implying that \( m = a^2 \), a perfect square. However, this contradicts the fact that \( m \) is square-free. Therefore, \( b \neq 0 \).
        
            \item \textbf{Case 2:} \( a = 0 \) \\
            If \( a = 0 \), then the equation becomes \( m = b^2 n \). Since \( m \) and \( n \) are both square-free, the only way for this equality to hold is if \( b^2 = 1 \). This gives \( b = \pm 1 \), and thus \( m = n \).
        \end{itemize}
        
        \noindent \textbf{Conclusion:} Both cases lead to a contradiction if \( m \neq n \), so the only possibility is \( m = n \). Therefore, there is a unique square-free integer \( m \neq 1 \) such that each quadratic field \( Q(\sqrt{m}) \) has a unique representation.
    \end{proof}

    \noindent \textbf{Recall:} If $\alpha$ is an algebraic integer, then $\alpha$ satisfies a monic polynomial with integer coefficients. If $f(x)$ is the minimal polynomial of $\alpha$, then $f(x)$ is monic, \( f(x) \in \mathbb{Q}[x] \), and \( f(x) \) divides any polynomial \( g(x) \in \mathbb{Q}[x] \) for which \( g(\alpha) = 0 \); i.e., \( g(x) = f(x)h(x) \) for some \( h(x) \in \mathbb{Q}[x] \).

Since both \( f(x) \) and \( g(x) \) are monic and \( g(x) \in \mathbb{Z}[x] \), by Gauss's Lemma, both \( f(x) \) and \( h(x) \) must be in \( \mathbb{Z}[x] \). Thus, we conclude that the \textbf{minimal polynomial of an algebraic integer has all coefficients in \( \mathbb{Z} \)}.

\vspace{0.5em}

Now we know that a quadratic field can be written as:
\[
\mathbb{Q}(\sqrt{m}) = \left\{ a + b\sqrt{m} : a, b \in \mathbb{Q} \right\},
\]
where \( m \) is a square-free integer. Alternatively, we can represent elements of \( \mathbb{Q}(\sqrt{m}) \) as
\[
\left\{ \frac{a + b\sqrt{m}}{c} : a, b, c \in \mathbb{Z}, \; c > 0 \right\}.
\]

\noindent
Algebraic integers in \(\mathbb{Q}\) are simply the usual integers, i.e., elements of \(\mathbb{Z}\), also called rational integers.\\\\

\thm{}{Let $\mathbb{Q}(\sqrt{m})$ , m square-free $\neq 1$, be a quadratic field. Then \\\\
(i) $a + b\sqrt{m}$, $a, b \in \mathbb{Z}$, are 
algebraic integers in $\mathbb{Q}(\sqrt{m})$.\\\\
(ii) If $m \equiv 1 \pmod{4}$, then  in addition $\frac{a + b\sqrt{m}}{2}$ with 
$a, b$ odd, are also algebraic integers. \\\\
(iii) Every algebraic integer in $\mathbb{Q}(\sqrt{m})$ is  one of these two types.}

\begin{proof}
(i) $a, b \in \mathbb{Z}$,$a + b\sqrt{m}$ is an algebraic integer because $a$, $b$ 
$\sqrt{m}$ are algebraic integers and the sum and product of algebraic integers are algebraic integers.\\\\

Or : Let $\alpha =  a + b\sqrt{m}$,  ($\alpha - a)^2 = m b^2$.
Therefore $\alpha$ satisfies a monic polynomial with integer coefficients, and therefore 
$\alpha$ is an algebraic integer.\\\\

(ii) Now consider the case where \( m \equiv 1 \pmod{4} \). Let us examine an element of the form \( \frac{a + b\sqrt{m}}{2} \). To determine whether this is an algebraic integer, consider the polynomial:
\[
\left( x - \frac{a + b\sqrt{m}}{2} \right) \left( x - \frac{a - b\sqrt{m}}{2} \right) = x^2 - ax + \frac{a^2 - m b^2}{4}.
\]
If \( a \) and \( b \) are odd and \( m \equiv 1 \pmod{4} \), we find that
\[
a^2 - m b^2 \equiv 1 - 1 \equiv 0 \pmod{4}.
\]
Therefore, the constant term \( \frac{a^2 - m b^2}{4} \) is an integer, and hence \( \frac{a + b\sqrt{m}}{2} \) satisfies a monic polynomial with integer coefficients. Thus, \( \frac{a + b\sqrt{m}}{2} \) is an algebraic integer.\\\\
(iii) Suppose $\alpha = \frac{a + b\sqrt{m}}{c}$, $a, b, c \in \mathbb{Z}$, $c > 0$ is an algebraic integer in $\mathbb{Q}(\sqrt{m})$. 
 Assume that $\gcd(a, b, c) = 1$. \\\\

\begin{itemize}
    \item If \( b = 0 \), then \( \alpha = \frac{a}{c} \), which is a rational number. For \( \alpha \) to be an algebraic integer, \( \frac{a}{c} \) must be a rational integer, which is true if and only if \( c \) divides \( a \) (i.e., \( c | a \)).

    \item Now suppose \( b \neq 0 \). Then \( \alpha \) is not a rational number, and the degree of \( \alpha \) is 2. In fact, \( \alpha \) satisfies the polynomial:
    \[
    \left(x - \frac{a + b\sqrt{m}}{c}\right)\left(x - \frac{a - b\sqrt{m}}{c}\right) = 0,
    \]
    which expands to
    \[
    x^2 - \frac{2a}{c} x + \frac{a^2 - m b^2}{c^2} = 0.
    \]
\end{itemize}

Since \( \alpha \) is an algebraic integer, this polynomial must have integer coefficients if it is the minimal polynomial of \( \alpha \). If \( b = 0 \), we know that \( c | a \), so the polynomial also has integer coefficients in this case. Therefore, for both \( b = 0 \) and \( b \neq 0 \), \( \alpha = \frac{a + b\sqrt{m}}{c} \) is an algebraic integer if and only if \( c | 2a \) and \( c^2 | (a^2 - m b^2) \).

\vspace{0.5em}
\noindent \textbf{Additional Considerations:}
\begin{itemize}
    \item Suppose \( (a, c) = 1 \). Let \( p \) be any prime dividing both \( a \) and \( c \). Then \( p^2 | c^2 \), so \( p^2 | (a^2 - m b^2) \). This implies \( p^2 | a^2 \) and \( p^2 | m b^2 \). Since \( m \) is square-free, we must have \( p^2 | b^2 \), which gives \( p | b \). Therefore, \( p \) divides \( a \), \( b \), and \( c \), which contradicts our assumption that \( \gcd(a, b, c) = 1 \). Thus, \( (a, c) = 1 \).

    \item If \( c > 2 \), then \( c | 2a \), implying \( (a, c) > 1 \), which is a contradiction. Therefore, \( c = 1 \) or \( c = 2 \).
\end{itemize}

\noindent 
\begin{itemize}
    \item If \( c = 1 \), then \( \alpha = a + b\sqrt{m} \) with \( a, b \in \mathbb{Z} \).
    \item If \( c = 2 \), we require \( 4 | (a^2 - m b^2) \). Since \( (a, c) = 1 \), \( a \) must be odd. We have:
    \[
    a^2 \text{ (odd)} - m b^2 \text{ (odd)} \equiv 0 \pmod{4},
    \]
    so \( b^2 m \) is odd, which implies that \( b \) is also odd.
\end{itemize}

Thus, if \( c = 2 \), both \( a \) and \( b \) must be odd, and we find that \( m \equiv 1 \pmod{4} \).

\vspace{0.5em}
Therefore:
\begin{itemize}
    \item For \( m \equiv 2 \text{ or } 3 \pmod{4} \), the algebraic integers in \( \mathbb{Q}(\sqrt{m}) \) are of the form \( a + b\sqrt{m} \), where \( a, b \in \mathbb{Z} \).
    \item For \( m \equiv 1 \pmod{4} \), the algebraic integers in \( \mathbb{Q}(\sqrt{m}) \) are of the following two types:
    \begin{enumerate}
        \item \( a + b\sqrt{m} \), where \( a, b \in \mathbb{Z} \).
        \item \( \frac{a + b\sqrt{m}}{2} \), where \( a \) and \( b \) are odd integers.
    \end{enumerate}
\end{itemize}

In other words, for \( m \equiv 1 \pmod{4} \), the algebraic integers can also be written as \( c + d \left(\frac{1 + \sqrt{m}}{2}\right) \), where \( c, d \in \mathbb{Z} \).
\end{proof}

\vspace{0.5em}
\noindent \textbf{Properties of Algebraic Integers:}
If \( \alpha \) and \( \beta \) are algebraic integers, then \( \alpha + \beta \), \( \alpha \beta \), and \( -\alpha \) are also algebraic integers. Thus, the set of all algebraic integers in an algebraic number field forms a subring of that field, and hence is itself a ring.

\prop{
Let \( \alpha \) be an algebraic number. Then there exists a \( c \in \mathbb{Z} \), \( c \neq 0 \), such that \( c\alpha \) is an algebraic integer.}

\begin{proof}
Suppose \( \alpha \) satisfies the polynomial
\[
a_0 \alpha^n + a_1 \alpha^{n-1} + \dots + a_n = 0,
\]
where \( a_i \in \mathbb{Z} \) and not all coefficients are zero. Assume \( a_0 \neq 0 \). Multiply the polynomial by \( a_0^{n-1} \) to obtain
\[
(a_0 \alpha)^n + a_1(a_0 \alpha)^{n-1} + a_2 a_0 (a_0 \alpha)^{n-2} + \dots + a_n a_0^{n-1} = 0.
\]
This shows that \( a_0 \alpha \) satisfies a monic polynomial with integer coefficients, which means \( a_0 \alpha \) is an algebraic integer. Let \( c = a_0 \).
\end{proof}

\subsection{Norm of an algebraic number in a quadratic field}

Let $\alpha \in K = \mathbb{Q}(\sqrt{m})$, where $m$ is square-free. Therefore 
$\alpha = \frac{a + b\sqrt{m}}{c}$, $a, b, c \in \mathbb{Z}$, $c \neq 0$. Then 
$\overline{\alpha} = \frac{a - b\sqrt{m}}{c}$ is called the conjugate of $\alpha$ in $Q(\sqrt{m})$.\\\\
$\alpha$ and $\overline{\alpha}$ are the roots of the quadratic polynomial $x^2 - \frac{2a}{c}x + \frac{a^2 - b^2m}{c^2} = 0$.\\\\
If $\alpha$ is an algebraic integer, then $\overline{\alpha}$ is also an algebraic integer.\\\\
$N(\alpha) =$ norm of $\alpha \in \mathbb{Q}(\sqrt{m})$ is defined as $N(\alpha) = \alpha \overline{\alpha} = \frac{a^2 - b^2m}{c^2}$.\\\\

\subsection{Units in Imaginary Quadratic Fields}



\end{document}
